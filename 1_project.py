# -*- coding: utf-8 -*-
"""1 project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xx_Xr_rpXreyTBfpo-xFRtN01I9JLKq5
"""

from google.colab import drive
drive.mount('/content/drive')

project_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris"

from google.colab import drive
import os

#drive.mount('/content/drive')

base_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris"
train_path = f"{base_path}/AOI_3_Paris_Train"

paths = {
    "rgb_tiff": f"{train_path}/RGB-PanSharpen",
    "geojson": f"{train_path}/geojson",
    "jpg_output": f"{base_path}/jpg_images",
    "yolo_labels": "/content/drive/MyDrive/projects/yolo_labels"
}

# Create JPG output folder if not exists
os.makedirs(paths["jpg_output"], exist_ok=True)



!pip install rasterio

import rasterio
from rasterio.plot import reshape_as_image
from PIL import Image
import os
import glob
import numpy as np

tiff_files = glob.glob(paths["rgb_tiff"] + "/*.tif")

for tif_path in tiff_files:
    with rasterio.open(tif_path) as src:
        img_array = src.read()
        img_array = reshape_as_image(img_array)

        # Normalize if necessary (convert to 0-255 range)
        if img_array.dtype != np.uint8:
            img_array = (255 * (img_array / np.max(img_array))).astype(np.uint8)

        img = Image.fromarray(img_array)
        filename = os.path.basename(tif_path).replace(".tif", ".jpg")
        img.save(os.path.join(paths["jpg_output"], filename), "JPEG")

print(f"‚úÖ Successfully converted {len(tiff_files)} TIFFs using rasterio.")

import os
import glob

jpg_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

jpg_files = glob.glob(os.path.join(jpg_dir, "*.jpg"))
print(f"‚úÖ Total JPG files found: {len(jpg_files)}")

# Show a few example file names
for f in jpg_files[:5]:
    print("üìÅ", os.path.basename(f))

import os
import glob

geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
geojson_files = glob.glob(os.path.join(geojson_dir, "*.geojson"))

print(f"üóÇÔ∏è Total geojson files: {len(geojson_files)}\n")

# Show few samples
for f in geojson_files[:5]:
    print("üìÑ", os.path.basename(f))

import os
import glob
import cv2
import geopandas as gpd
import matplotlib.pyplot as plt

# Paths
jpg_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
output_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/visualized_buildings"

os.makedirs(output_dir, exist_ok=True)

# Loop through geojson files
geojson_files = glob.glob(os.path.join(geojson_dir, "*.geojson"))

for geojson_path in geojson_files[:10]:  # Preview first 10 for speed
    base = os.path.basename(geojson_path).replace("buildings_", "").replace(".geojson", ".jpg")
    jpg_path = os.path.join(jpg_dir, base)

    if not os.path.exists(jpg_path):
        print(f"‚ùå Missing image for {base}")
        continue

    # Read image
    img = cv2.imread(jpg_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Read geojson
    gdf = gpd.read_file(geojson_path)

    # Plot
    fig, ax = plt.subplots(figsize=(8, 8))
    ax.imshow(img_rgb)
    gdf.boundary.plot(ax=ax, color='red', linewidth=0.5)
    ax.set_title(base)
    ax.axis("off")

    # Save
    save_path = os.path.join(output_dir, base)
    plt.savefig(save_path, bbox_inches="tight")
    plt.close()

print("‚úÖ Visualization complete and saved in 'visualized_buildings' folder.")

import os
import glob
import numpy as np
import geopandas as gpd
import matplotlib.pyplot as plt
from PIL import Image

# Mount Drive first if not already
from google.colab import drive
drive.mount('/content/drive')

# Define your paths
project_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train"
image_dir = os.path.join(project_dir, "jpg_images")
geojson_dir = os.path.join(project_dir, "geojson/buildings")
output_dir = os.path.join(project_dir, "visualized_buildings")
os.makedirs(output_dir, exist_ok=True)

# Get image and geojson files
image_files = sorted(glob.glob(os.path.join(image_dir, "*.jpg")))
geojson_files = sorted(glob.glob(os.path.join(geojson_dir, "*.geojson")))

# Create a dictionary for quick image lookup
image_dict = {
    os.path.basename(img).replace(".jpg", ""): img for img in image_files
}

# Loop through geojson files
for geojson_path in geojson_files:
    img_id = os.path.basename(geojson_path).replace("buildings_", "").replace(".geojson", "")

    if img_id not in image_dict:
        print(f"‚ùå Missing image for {img_id}.jpg")
        continue

    try:
        image = np.array(Image.open(image_dict[img_id]))
        gdf = gpd.read_file(geojson_path)

        # Skip if geojson is empty or invalid
        if gdf.empty or gdf.geometry.is_empty.all():
            print(f"‚ö†Ô∏è Skipping {img_id}.geojson ‚Äî empty or invalid geometry")
            continue

        # Plot image with overlaid buildings
        fig, ax = plt.subplots(figsize=(10, 10))
        ax.imshow(image, aspect='auto')  # Prevent ValueError
        gdf.plot(ax=ax, facecolor='none', edgecolor='lime', linewidth=1)
        ax.set_title(img_id)
        ax.axis('off')

        # Save visualization
        save_path = os.path.join(output_dir, f"{img_id}.png")
        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)
        plt.close()
        print(f"‚úÖ Visualized: {img_id}")

    except Exception as e:
        print(f"‚ùå Failed to process {img_id}: {e}")

"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/visualized_buildings"

import os
import glob
import json
from PIL import Image

# Define paths
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
yolo_dir = "/content/drive/MyDrive/projects/yolo_labels"

os.makedirs(yolo_dir, exist_ok=True)

def polygon_to_bbox(polygon):
    x_coords = [p[0] for p in polygon]
    y_coords = [p[1] for p in polygon]
    x_min, x_max = min(x_coords), max(x_coords)
    y_min, y_max = min(y_coords), max(y_coords)
    x_center = (x_min + x_max) / 2
    y_center = (y_min + y_max) / 2
    width = x_max - x_min
    height = y_max - y_min
    return x_center, y_center, width, height

geojson_files = glob.glob(os.path.join(geojson_dir, "*.geojson"))

for geojson_path in geojson_files:
    with open(geojson_path) as f:
        data = json.load(f)

    # Match JPG filename
    base_name = os.path.splitext(os.path.basename(geojson_path))[0]
    image_name = base_name.replace("buildings_", "") + ".jpg"
    image_path = os.path.join(image_dir, image_name)

    if not os.path.exists(image_path):
        print(f"‚ùå Skipping: {image_name} (image not found)")
        continue

    img = Image.open(image_path)
    width, height = img.size

    yolo_txt_path = os.path.join(yolo_dir, base_name.replace("buildings_", "") + ".txt")
    with open(yolo_txt_path, "w") as out_file:
        for feature in data["features"]:
            coords = feature["geometry"]["coordinates"][0]
            x_center, y_center, w_box, h_box = polygon_to_bbox(coords)

            # Normalize for YOLO
            x_center /= width
            y_center /= height
            w_box /= width
            h_box /= height

            # class_id = 0 for 'building'
            out_file.write(f"0 {x_center:.6f} {y_center:.6f} {w_box:.6f} {h_box:.6f}\n")

print("‚úÖ YOLO label files generated and saved in:", yolo_dir)

import os
import shutil
from glob import glob

# Paths
img_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
label_dir = "/content/drive/MyDrive/projects/yolo_labels"
dataset_dir = "/content/drive/MyDrive/projects/yolo_dataset"
images_train = os.path.join(dataset_dir, "images", "train")
labels_train = os.path.join(dataset_dir, "labels", "train")

# Create folders
os.makedirs(images_train, exist_ok=True)
os.makedirs(labels_train, exist_ok=True)

# Match JPGs and corresponding YOLO labels
jpg_files = glob(os.path.join(img_dir, "*.jpg"))

copied = 0
for jpg_path in jpg_files:
    base = os.path.splitext(os.path.basename(jpg_path))[0]
    label_path = os.path.join(label_dir, base + ".txt")

    if os.path.exists(label_path):
        shutil.copy2(jpg_path, os.path.join(images_train, os.path.basename(jpg_path)))
        shutil.copy2(label_path, os.path.join(labels_train, os.path.basename(label_path)))
        copied += 1

print(f"‚úÖ Copied {copied} image-label pairs to YOLO dataset folder.")

import glob

label_dir = "/content/drive/MyDrive/projects/yolo_labels"
txt_files = glob.glob(label_dir + "/*.txt")
print(f"‚úÖ Total YOLO label files found: {len(txt_files)}")
print("üîé Sample label file names:")
for f in txt_files[:5]:
    print("üìÑ", os.path.basename(f))

img_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

match_count = 0
for label_file in txt_files:
    base = os.path.splitext(os.path.basename(label_file))[0]
    image_file = os.path.join(img_dir, base + ".jpg")
    if os.path.exists(image_file):
        match_count += 1

print(f"‚úÖ Total label-image matches found: {match_count}")

import os
import glob
import shutil

jpg_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
renamed_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images"
os.makedirs(renamed_dir, exist_ok=True)

jpg_files = glob.glob(os.path.join(jpg_dir, "*.jpg"))
renamed_count = 0

for path in jpg_files:
    old_name = os.path.basename(path)
    # Extract image ID
    if "img" in old_name:
        img_id = old_name.split("img")[-1].replace(".jpg", "")
        new_name = f"AOI_3_Paris_img{img_id}.jpg"
        new_path = os.path.join(renamed_dir, new_name)
        shutil.copy2(path, new_path)
        renamed_count += 1

print(f"‚úÖ Renamed and copied {renamed_count} images to '{renamed_dir}'")

import os
import shutil
import glob

# Paths
images_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images"
labels_dir = "/content/drive/MyDrive/projects/yolo_labels"
yolo_dataset_dir = "/content/drive/MyDrive/projects/yolo_dataset"
images_out = os.path.join(yolo_dataset_dir, "images")
labels_out = os.path.join(yolo_dataset_dir, "labels")

# Create folders
os.makedirs(images_out, exist_ok=True)
os.makedirs(labels_out, exist_ok=True)

# Match and copy
matched = 0
for label_file in glob.glob(os.path.join(labels_dir, "*.txt")):
    base_name = os.path.basename(label_file).replace(".txt", ".jpg")
    image_file = os.path.join(images_dir, base_name)

    if os.path.exists(image_file):
        shutil.copy2(image_file, os.path.join(images_out, base_name))
        shutil.copy2(label_file, os.path.join(labels_out, os.path.basename(label_file)))
        matched += 1

print(f"‚úÖ Copied {matched} image-label pairs to YOLO dataset folder.")

import os
import random
import shutil
from tqdm import tqdm

# Paths
base_dir = "/content/drive/MyDrive/projects/yolo_dataset"
img_dir = os.path.join(base_dir, "images")
lbl_dir = os.path.join(base_dir, "labels")

train_img_dir = os.path.join(img_dir, "train")
val_img_dir = os.path.join(img_dir, "val")
train_lbl_dir = os.path.join(lbl_dir, "train")
val_lbl_dir = os.path.join(lbl_dir, "val")

# Create directories
for d in [train_img_dir, val_img_dir, train_lbl_dir, val_lbl_dir]:
    os.makedirs(d, exist_ok=True)

# List of all image files
image_files = sorted([f for f in os.listdir(img_dir) if f.endswith(".jpg")])
random.shuffle(image_files)

# Split: 90% train, 10% val
split_idx = int(len(image_files) * 0.9)
train_files = image_files[:split_idx]
val_files = image_files[split_idx:]

# Helper to copy files
def copy_files(file_list, src_img, src_lbl, dst_img, dst_lbl):
    for file in tqdm(file_list, desc=f"Copying to {dst_img.split('/')[-1]}"):
        img_src = os.path.join(src_img, file)
        lbl_src = os.path.join(src_lbl, file.replace(".jpg", ".txt"))

        img_dst = os.path.join(dst_img, file)
        lbl_dst = os.path.join(dst_lbl, file.replace(".jpg", ".txt"))

        shutil.copy2(img_src, img_dst)
        if os.path.exists(lbl_src):
            shutil.copy2(lbl_src, lbl_dst)

copy_files(train_files, img_dir, lbl_dir, train_img_dir, train_lbl_dir)
copy_files(val_files, img_dir, lbl_dir, val_img_dir, val_lbl_dir)

print("‚úÖ Dataset split into train and val folders.")

data_yaml = """
path: /content/drive/MyDrive/projects/yolo_dataset
train: images/train
val: images/val

nc: 1
names: ['building']
"""

# Save the file
with open('/content/drive/MyDrive/projects/yolo_dataset/data.yaml', 'w') as f:
    f.write(data_yaml)

print("‚úÖ data.yaml created successfully!")

"/content/drive/MyDrive/projects/yolo_dataset/data.yaml"

!pip install ultralytics --upgrade -q

from ultralytics import YOLO

# Load pre-trained YOLOv8 model (use 'yolov8n.pt' for nano, 's', 'm', 'l' or 'x' for others)
model = YOLO('yolov8l.pt')  # You can change to yolov8s.pt or yolov8m.pt depending on GPU

# Train the model using your dataset
model.train(
    data="/content/drive/MyDrive/projects/yolo_dataset/data.yaml",
    epochs=50,
    imgsz=640,
    batch=8,
    project="/content/drive/MyDrive/projects/yolo_training",
    name="building_detector",
    exist_ok=True
)

!yolo task=detect mode=train model=yolov8x.pt data='/content/drive/MyDrive/projects/yolo_dataset/data.yaml' epochs=50 imgsz=640 save=True project='/content/drive/MyDrive/projects/yolo_outputs' name='building_detection' exist_ok=True

from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/projects/yolo_outputs/building_detection/weights/best.pt")

results = model.predict(
    source="/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images",
    conf=0.5,
    iou=0.45,
    save=True,
    project="/content/drive/MyDrive/projects/yolo_predictions",
    name="buildings_run1",
    exist_ok=True
)

!pip install geopandas rasterio shapely --quiet

import os
import rasterio
import pandas as pd
from shapely.geometry import box
from glob import glob

# Paths
tiff_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen"
pred_dir = "/content/drive/MyDrive/projects/yolo_predictions/buildings_run1/labels"
output_csv = "/content/drive/MyDrive/projects/yolo_predictions/predicted_coordinates.csv"

data = []

# Loop through YOLO prediction files
for txt_path in glob(f"{pred_dir}/*.txt"):
    image_name = os.path.basename(txt_path).replace(".txt", ".tif")
    tiff_path = os.path.join(tiff_dir, image_name)

    # Skip if tif doesn't exist
    if not os.path.exists(tiff_path):
        print(f"Skipping: {image_name} (TIFF not found)")
        continue

    # Open GeoTIFF for metadata
    with rasterio.open(tiff_path) as src:
        width, height = src.width, src.height
        transform = src.transform

        # Read YOLO detections
        with open(txt_path, "r") as f:
            for line in f:
                cls, x_center, y_center, w, h = map(float, line.strip().split())

                # Convert YOLO normalized ‚Üí pixel coords
                x1 = (x_center - w / 2) * width
                y1 = (y_center - h / 2) * height
                x2 = (x_center + w / 2) * width
                y2 = (y_center + h / 2) * height

                # Convert pixel ‚Üí geo coords
                lon1, lat1 = src.xy(y1, x1)
                lon2, lat2 = src.xy(y2, x2)

                # Midpoint
                mid_lat = (lat1 + lat2) / 2
                mid_lon = (lon1 + lon2) / 2

                data.append({
                    "image": image_name,
                    "class_id": int(cls),
                    "latitude": mid_lat,
                    "longitude": mid_lon
                })

# Save to CSV
df = pd.DataFrame(data)
df.to_csv(output_csv, index=False)
print(f"‚úÖ Geo-coordinates saved to: {output_csv}")

import glob
import os

label_dir = '/content/drive/MyDrive/projects/yolo_predictions/buildings_run1/labels'
txt_files = glob.glob(os.path.join(label_dir, '*.txt'))

print(f"üì¶ Total label files: {len(txt_files)}")

# Show a few sample lines
for f in txt_files[:3]:
    print(f"\nüìÑ File: {os.path.basename(f)}")
    with open(f, 'r') as file:
        lines = file.readlines()
        print(lines[:5])  # Show top 5 lines

from ultralytics import YOLO

model = YOLO('/content/drive/MyDrive/projects/yolo_training/building_detector/weights/best.pt')

results = model.predict(
    source='/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images',
    conf=0.5,
    iou=0.45,
    save=True,
    save_txt=True,  # ‚úÖ Save label files (YOLO format)
    project='/content/drive/MyDrive/projects/yolo_predictions',
    name='buildings_run1',
    exist_ok=True
)

import os
import pandas as pd
import rasterio
import glob

# Paths
geo_image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen"
label_dir = "/content/drive/MyDrive/projects/yolo_predictions/buildings_run1/labels"
output_csv = "/content/drive/MyDrive/projects/yolo_predictions/predicted_coordinates.csv"

rows = []

for label_path in glob.glob(os.path.join(label_dir, "*.txt")):
    base_name = os.path.basename(label_path).replace(".txt", "")
    image_name = base_name + ".tif"
    image_path = os.path.join(geo_image_dir, image_name)

    if not os.path.exists(image_path):
        print(f"‚ùå Image not found for {image_name}")
        continue

    with rasterio.open(image_path) as src:
        width, height = src.width, src.height
        transform = src.transform

        with open(label_path, "r") as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) != 6: continue  # YOLOv8 format: cls x y w h conf
                _, x_center, y_center, _, _, conf = map(float, parts)

                # Convert normalized coords to pixel
                px = int(x_center * width)
                py = int(y_center * height)

                # Convert to geo-coordinates
                lon, lat = src.xy(py, px)
                rows.append([base_name + ".jpg", lat, lon, conf])

# Save all to CSV
df = pd.DataFrame(rows, columns=["image", "latitude", "longitude", "confidence"])
df.to_csv(output_csv, index=False)

print(f"‚úÖ Geo-coordinates saved to: {output_csv}")

import pandas as pd
import folium

# Load CSV with lat/lon predictions
csv_path = "/content/drive/MyDrive/projects/yolo_predictions/predicted_coordinates.csv"
df = pd.read_csv(csv_path)

# Create base map (centered around Paris)
m = folium.Map(location=[48.8566, 2.3522], zoom_start=13)

# Add markers
for _, row in df.iterrows():
    folium.CircleMarker(
        location=[row["latitude"], row["longitude"]],
        radius=3,
        color="red",
        fill=True,
        fill_opacity=0.7,
        popup=f"{row['image']}<br>Confidence: {row['confidence']:.2f}"
    ).add_to(m)

# Save map
map_path = "/content/drive/MyDrive/projects/yolo_predictions/detection_map.html"
m.save(map_path)
print(f"‚úÖ Map saved to: {map_path}")

import cv2
import matplotlib.pyplot as plt
import glob
import os

# Path to annotated images (after prediction)
pred_path = '/content/drive/MyDrive/projects/yolo_predictions/buildings_run1'
images = sorted(glob.glob(os.path.join(pred_path, '*.jpg')))

# Show first 5 results
for img_path in images[:5]:
    img = cv2.imread(img_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    plt.figure(figsize=(8, 8))
    plt.imshow(img_rgb)
    plt.title(os.path.basename(img_path))
    plt.axis('off')
    plt.show()

from ultralytics import YOLO

model = YOLO('/content/drive/MyDrive/projects/yolo_training/building_detector/weights/best.pt')
results = model.predict('/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images', save=False)

for i, r in enumerate(results[:10]):
    print(f"Image {i+1}: {len(r.boxes)} buildings detected")

from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/projects/yolo_training/building_detector/weights/best.pt")
results = model.predict(source="your_test_images_folder", conf=0.5, save=True)

import pandas as pd
import folium
from folium.plugins import MarkerCluster

# Load coordinates
csv_path = "/content/drive/MyDrive/projects/yolo_predictions/predicted_coordinates.csv"
df = pd.read_csv(csv_path)

# Initialize map centered at Paris (you can adjust the default center)
m = folium.Map(location=[48.8566, 2.3522], zoom_start=13)

# Add markers
marker_cluster = MarkerCluster().add_to(m)

for idx, row in df.iterrows():
    lat, lon = row['latitude'], row['longitude']
    folium.Marker(
        location=[lat, lon],
        popup=f"Detected Building in {row['image']}",
        icon=folium.Icon(color="red", icon="home")
    ).add_to(marker_cluster)

# Save map
map_output = "/content/drive/MyDrive/projects/yolo_predictions/building_map.html"
m.save(map_output)

print(f"‚úÖ Map saved to: {map_output}")

from ultralytics import YOLO

# Load your trained model
model = YOLO("/content/drive/MyDrive/projects/yolo_training/building_detector/weights/best.pt")

# Run inference on real test images
results = model.predict(
    source="/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/renamed_images",  # ‚úÖ Replace with your actual test folder
    save=True,
    conf=0.5,
    iou=0.45,
    project="/content/drive/MyDrive/projects/yolo_predictions",
    name="testing_inference",
    exist_ok=True
)

# ‚úÖ MASK R-CNN TRAINING NOTEBOOK for Paris Dataset
#--------------------------------------------------
# üß† Step 0: Install Detectron2 (Facebook/Meta)
!pip install -q torch torchvision torchaudio
!pip install -q git+https://github.com/facebookresearch/detectron2.git

# üóÇÔ∏è Step 1: Mount Google Drive
from google.colab import drive
import os

drive.mount('/content/drive')
project_root = "/content/drive/MyDrive/projects/mask_rcnn_paris"
os.makedirs(project_root, exist_ok=True)

# üì¶ Step 2: Dependencies for annotation conversion
!pip install -q pycocotools geopandas shapely rasterio

import os, json, glob
import geopandas as gpd
from shapely.geometry import mapping
from PIL import Image
from tqdm import tqdm

# üìÇ Input paths
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen"
output_json = f"{project_root}/instances_train.json"

# üîÅ Step 3: Convert geojson ‚Üí COCO format for Detectron2
images, annotations = [], []
image_id, annotation_id = 0, 0
categories = [{"id": 1, "name": "building"}]

for geojson_file in tqdm(sorted(glob.glob(f"{geojson_dir}/*.geojson"))):
    base = os.path.basename(geojson_file).replace(".geojson", ".tif")
    img_path = os.path.join(image_dir, base)
    if not os.path.exists(img_path): continue

    with Image.open(img_path) as img:
        width, height = img.size

    images.append({"id": image_id, "file_name": base, "height": height, "width": width})

    gdf = gpd.read_file(geojson_file)
    for _, row in gdf.iterrows():
        poly = row["geometry"]
        if poly is None: continue
        segmentation = [list(sum(poly.exterior.coords[:-1], ()))[:]]
        annotations.append({
            "id": annotation_id,
            "image_id": image_id,
            "category_id": 1,
            "segmentation": segmentation,
            "bbox": list(poly.bounds),
            "iscrowd": 0,
            "area": poly.area
        })
        annotation_id += 1
    image_id += 1

with open(output_json, 'w') as f:
    json.dump({"images": images, "annotations": annotations, "categories": categories}, f)

print(f"‚úÖ COCO annotations saved: {output_json}")

# ‚úÖ Step 4: Register dataset in Detectron2
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.data.datasets import register_coco_instances
from detectron2 import model_zoo

register_coco_instances("buildings_paris", {}, output_json, image_dir)

# ‚öôÔ∏è Step 5: Configure Mask R-CNN
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("buildings_paris",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 1500
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
cfg.OUTPUT_DIR = f"{project_root}/output"
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

# üöÄ Step 6: Train the model
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

# üíæ Step 7: Save final model
print("\n‚úÖ Training complete. Model saved at:", f"{cfg.OUTPUT_DIR}/model_final.pth")

"/content/drive/MyDrive/projects/mask_rcnn_paris/coco_annotations.json"

from detectron2.data.datasets import register_coco_instances
import os

# Paths
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
images_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"

# STEP 4: Register the COCO dataset with a NEW NAME to avoid conflict
register_coco_instances("buildings_paris_v2", {}, json_path, images_path)

# STEP 5: Config setup
from detectron2.config import get_cfg
from detectron2.engine import DefaultTrainer
from detectron2 import model_zoo

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("buildings_paris_v2",)
cfg.DATASETS.TEST = ()  # no test dataset
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 300  # 300 for now
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only buildings
cfg.OUTPUT_DIR = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

!pip install -q torch torchvision torchaudio
!pip install -q git+https://github.com/facebookresearch/detectron2.git

import os
import json
import torch
from detectron2.utils.logger import setup_logger
setup_logger()

from detectron2 import model_zoo
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.datasets import register_coco_instances
from detectron2.utils.visualizer import Visualizer
from detectron2.data import build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

dataset_path = "/content/drive/MyDrive/projects/mask_rcnn_paris"
images_path = os.path.join(dataset_path, "images")
json_path = os.path.join(dataset_path, "instances_train.json")

from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.data.datasets import register_coco_instances

# Set your paths
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
images_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"

# üßπ Clear any previous registration to avoid path conflicts
if "buildings_paris" in DatasetCatalog.list():
    DatasetCatalog.remove("buildings_paris")
    MetadataCatalog.remove("buildings_paris")

# ‚úÖ Register the COCO-style dataset
register_coco_instances("buildings_paris", {}, json_path, images_path)

# ‚úÖ Get the metadata and dataset dicts
metadata = MetadataCatalog.get("buildings_paris")
dataset_dicts = DatasetCatalog.get("buildings_paris")

# ‚úÖ Check how many samples were loaded
print("Total samples loaded:", len(dataset_dicts))

import json

json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

with open(json_path, 'r') as f:
    data = json.load(f)

print("Images:", len(data.get("images", [])))
print("Annotations:", len(data.get("annotations", [])))
print("Categories:", len(data.get("categories", [])))

!pip install geojson

import os
import json
import glob
import cv2
import geojson
from shapely.geometry import shape, Polygon, MultiPolygon, mapping

# Paths
images_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
output_json = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

# Init COCO structure
coco_output = {
    "images": [],
    "annotations": [],
    "categories": [{"id": 1, "name": "building"}]
}

annotation_id = 1
image_id = 1

image_files = sorted(glob.glob(os.path.join(images_dir, "*.jpg")))

for image_path in image_files:
    image_filename = os.path.basename(image_path)
    img_name = os.path.splitext(image_filename)[0]
    geojson_path = os.path.join(geojson_dir, f"buildings_{img_name}.geojson")

    if not os.path.exists(geojson_path):
        continue

    img = cv2.imread(image_path)
    height, width = img.shape[:2]

    # Add image entry
    coco_output["images"].append({
        "id": image_id,
        "file_name": image_filename,
        "height": height,
        "width": width
    })

    with open(geojson_path) as f:
        gj = geojson.load(f)
        for feature in gj["features"]:
            geom = shape(feature["geometry"])
            if geom.is_empty:
                continue
            if isinstance(geom, Polygon):
                coords = [list(geom.exterior.coords)]
            elif isinstance(geom, MultiPolygon):
                coords = [list(p.exterior.coords) for p in geom.geoms]
            else:
                continue

            segmentation = []
            for poly in coords:
                flat = [coord for point in poly for coord in point]
                segmentation.append(flat)

            x, y, max_x, max_y = geom.bounds
            width_box = max_x - x
            height_box = max_y - y

            coco_output["annotations"].append({
                "id": annotation_id,
                "image_id": image_id,
                "category_id": 1,
                "segmentation": segmentation,
                "area": geom.area,
                "bbox": [x, y, width_box, height_box],
                "iscrowd": 0
            })
            annotation_id += 1

    image_id += 1

# Save final COCO JSON
with open(output_json, "w") as f:
    json.dump(coco_output, f)

print(f"‚úÖ COCO-style annotations saved to: {output_json}")

with open(output_json) as f:
    data = json.load(f)
print("Images:", len(data["images"]))
print("Annotations:", len(data["annotations"]))

from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog, DatasetCatalog

dataset_name = "buildings_paris"
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
images_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"

# Register once
if dataset_name in DatasetCatalog.list():
    DatasetCatalog.remove(dataset_name)
    MetadataCatalog.remove(dataset_name)

register_coco_instances(dataset_name, {}, json_path, images_path)

# Check loaded metadata
metadata = MetadataCatalog.get(dataset_name)
dataset_dicts = DatasetCatalog.get(dataset_name)
print("‚úÖ Total annotations loaded:", len(dataset_dicts))

import os
import json
import cv2
import glob
import geojson
from shapely.geometry import shape, Polygon, MultiPolygon, mapping

# Paths
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_json = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

images = []
annotations = []
image_id = 0
annotation_id = 0

for geo_path in sorted(glob.glob(os.path.join(geojson_dir, "*.geojson"))):
    base_name = os.path.basename(geo_path).replace("buildings_", "").replace(".geojson", ".jpg")

    image_path = os.path.join(image_dir, base_name)

    if not os.path.exists(image_path):
        continue

    img = cv2.imread(image_path)
    height, width = img.shape[:2]

    images.append({
        "file_name": base_name,
        "height": height,
        "width": width,
        "id": image_id
    })

    with open(geo_path) as f:
        gj = geojson.load(f)

    for feature in gj["features"]:
        geom = shape(feature["geometry"])
        if not geom.is_valid:
            continue

        if isinstance(geom, Polygon):
            coords = [list(geom.exterior.coords)]
        elif isinstance(geom, MultiPolygon):
            coords = [list(p.exterior.coords) for p in geom.geoms]
        else:
            continue

        for segment in coords:
            segmentation = [list(sum(segment, ()))]
            x_coords = [pt[0] for pt in segment]
            y_coords = [pt[1] for pt in segment]
            x_min, y_min = min(x_coords), min(y_coords)
            x_max, y_max = max(x_coords), max(y_coords)
            bbox = [x_min, y_min, x_max - x_min, y_max - y_min]

            annotations.append({
                "segmentation": segmentation,
                "area": geom.area,
                "iscrowd": 0,
                "image_id": image_id,
                "bbox": bbox,
                "category_id": 0,
                "id": annotation_id
            })
            annotation_id += 1

    image_id += 1

# Final structure
coco = {
    "images": images,
    "annotations": annotations,
    "categories": [{"id": 0, "name": "building"}]
}

with open(output_json, "w") as f:
    json.dump(coco, f)

print(f"‚úÖ COCO annotations written to {output_json}")
print(f"Images: {len(images)}, Annotations: {len(annotations)}")

import json
import os

sample = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings/buildings_AOI_3_Paris_img1234.geojson"  # Use any file path
with open(sample) as f:
    data = json.load(f)

print("Keys:", data.keys())
print("Type:", type(data.get('features')))
print("Num of Features:", len(data.get('features', [])))
print("First feature example:", data.get('features', [])[0] if data.get('features') else "No features found")

import os

img_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"
test_image = "AOI_3_Paris_img1234.jpg"  # Replace with a real one from your folder
print("Exists:", os.path.exists(os.path.join(img_dir, test_image)))

import os, json, glob
from shapely.geometry import shape
from tqdm import tqdm

geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/images"
output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

images = []
annotations = []
annotation_id = 0
image_id = 0

geojson_files = glob.glob(os.path.join(geojson_dir, "*.geojson"))

for geo_path in tqdm(geojson_files):
    base_name = os.path.basename(geo_path).replace("buildings_", "").replace(".geojson", ".jpg")
    img_path = os.path.join(image_dir, base_name)

    if not os.path.exists(img_path):
        continue  # Skip if matching image doesn't exist

    with open(geo_path) as f:
        data = json.load(f)

    images.append({
        "id": image_id,
        "file_name": base_name,
        "height": 650,
        "width": 650
    })

    for feature in data.get("features", []):
        geom = feature.get("geometry", None)
        if geom and geom.get("type") == "Polygon":
            coords = shape(geom).exterior.coords
            poly = [p for xy in coords for p in xy]

            annotations.append({
                "id": annotation_id,
                "image_id": image_id,
                "category_id": 0,
                "segmentation": [poly],
                "area": shape(geom).area,
                "bbox": list(shape(geom).bounds),
                "iscrowd": 0
            })
            annotation_id += 1

    image_id += 1

coco_output = {
    "images": images,
    "annotations": annotations,
    "categories": [{"id": 0, "name": "building"}]
}

with open(output_path, "w") as f:
    json.dump(coco_output, f)

print(f"‚úÖ COCO annotations written to {output_path}")
print(f"Images: {len(images)}, Annotations: {len(annotations)}")

import json

with open('/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings/buildings.geojson') as f:
    data = json.load(f)

for feature in data['features'][:5]:
    print(feature['properties']['image_id'])  # Make sure this key exists!

import os

geojson_dir = '/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings'

# List all .geojson files in the folder
for file in os.listdir(geojson_dir):
    if file.endswith('.geojson'):
        print(file)

'/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings/AOI_3_Paris_img.geojson'

import json

correct_path = '/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings/your_file.geojson'

with open(correct_path) as f:
    data = json.load(f)

print("Loaded features:", len(data['features']))

import os
from glob import glob

geojson_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_json = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

import os
import json
from glob import glob
from shapely.geometry import shape
from tqdm import tqdm

geojson_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_json = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

images = []
annotations = []
categories = [{"id": 1, "name": "building"}]
ann_id = 1
img_id = 1

geojson_files = sorted(glob(os.path.join(geojson_folder, "*.geojson")))

for geojson_file in tqdm(geojson_files):
    filename = os.path.basename(geojson_file).replace(".geojson", ".jpg")
    img_path = os.path.join(image_folder, filename)
    if not os.path.exists(img_path):
        continue

    images.append({
        "id": img_id,
        "file_name": filename,
        "width": 650,
        "height": 650
    })

    with open(geojson_file) as f:
        data = json.load(f)

    for feature in data["features"]:
        geom = shape(feature["geometry"])
        if not geom.is_valid:
            continue
        coords = list(geom.exterior.coords)
        coords = [c for xy in coords for c in xy]  # flatten
        annotations.append({
            "id": ann_id,
            "image_id": img_id,
            "category_id": 1,
            "segmentation": [coords],
            "bbox": list(geom.bounds),
            "area": geom.area,
            "iscrowd": 0
        })
        ann_id += 1

    img_id += 1

# Save COCO-style JSON
coco_dict = {
    "images": images,
    "annotations": annotations,
    "categories": categories
}

with open(output_json, "w") as f:
    json.dump(coco_dict, f)

print(f"‚úÖ Saved {len(images)} images and {len(annotations)} annotations to {output_json}")

import os
print(len(os.listdir("/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images")))

geojson_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

from glob import glob
import os

geojson_files = sorted(glob(os.path.join(geojson_folder, "*.geojson")))

for geojson_file in geojson_files[:5]:  # Test first 5 files
    filename = os.path.basename(geojson_file).replace(".geojson", ".jpg")
    img_path = os.path.join(image_folder, filename)
    print("Looking for:", img_path, "‚Üí Exists?", os.path.exists(img_path))

with open(output_json) as f:
    data = json.load(f)

print("Images:", len(data["images"]))
print("Annotations:", len(data["annotations"]))

image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

import os

# Example check
test_file = "buildings_AOI_3_Paris_img1234.jpg"
print("Exists?", os.path.exists(f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/{test_file}"))

import os
import json
from tqdm import tqdm

geojson_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

images = []
annotations = []
categories = [{"id": 1, "name": "building"}]
image_id = 0
annotation_id = 0

geojson_files = sorted(os.listdir(geojson_folder))

for geojson_file in tqdm(geojson_files):
    if not geojson_file.endswith(".geojson"):
        continue

    # ‚úÖ FIX: Remove 'buildings_' prefix from filename to match image
    image_filename = geojson_file.replace("buildings_", "").replace(".geojson", ".jpg")
    image_path = os.path.join(image_folder, image_filename)

    if not os.path.exists(image_path):
        continue

    with open(os.path.join(geojson_folder, geojson_file)) as f:
        data = json.load(f)

    height, width = 1024, 1024  # adjust if needed
    images.append({
        "id": image_id,
        "file_name": image_filename,
        "height": height,
        "width": width,
    })

    for feature in data["features"]:
        if feature["geometry"]["type"] != "Polygon":
            continue

        coords = feature["geometry"]["coordinates"][0]
        segmentation = [coord for xy in coords for coord in xy]
        x_coords = [pt[0] for pt in coords]
        y_coords = [pt[1] for pt in coords]
        x_min, y_min = min(x_coords), min(y_coords)
        width_box, height_box = max(x_coords) - x_min, max(y_coords) - y_min

        annotations.append({
            "id": annotation_id,
            "image_id": image_id,
            "category_id": 1,
            "segmentation": [segmentation],
            "bbox": [x_min, y_min, width_box, height_box],
            "area": width_box * height_box,
            "iscrowd": 0,
        })
        annotation_id += 1

    image_id += 1

# ‚úÖ Save in COCO format
coco_output = {
    "images": images,
    "annotations": annotations,
    "categories": categories,
}

with open(output_path, "w") as f:
    json.dump(coco_output, f)

print("‚úÖ COCO-style annotations saved to:", output_path)
print("Images:", len(images), "Annotations:", len(annotations))

# üîç Debug check for existing pair
import os

geojson_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

test_geojson = "buildings_AOI_3_Paris_img1017.geojson"
test_image = test_geojson.replace("buildings_", "").replace(".geojson", ".jpg")
image_path = os.path.join(image_folder, test_image)

print("Looking for image:", image_path)
print("Exists?", os.path.exists(image_path))

import os

image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen"
test_file = "AOI_3_Paris_img1017.jpg"
print("Exists?", os.path.exists(os.path.join(image_folder, test_file)))

import os

folder_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen"
all_files = os.listdir(folder_path)

# Print 10 image filenames
print("Sample files from folder:")
print(all_files[:10])

import os, json, glob
from shapely.geometry import shape
from PIL import Image

# Paths
jpg_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
output_json = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"

# Init COCO structure
coco_dict = {
    "images": [],
    "annotations": [],
    "categories": [{"id": 1, "name": "building"}]
}

annotation_id = 1

for img_path in sorted(glob.glob(jpg_dir + "/*.jpg")):
    img_name = os.path.basename(img_path)
    img_id = int(img_name.split("img")[1].split(".")[0])

    # Corresponding geojson file
    geo_path = os.path.join(geojson_dir, f"buildings_AOI_3_Paris_img{img_id}.geojson")
    if not os.path.exists(geo_path):
        continue

    # Get image size
    with Image.open(img_path) as im:
        width, height = im.size

    # Add image entry
    coco_dict["images"].append({
        "id": img_id,
        "file_name": img_name,
        "width": width,
        "height": height
    })

    # Read geojson
    with open(geo_path) as f:
        gj = json.load(f)

    for feature in gj['features']:
        geom = shape(feature['geometry'])
        if geom.geom_type != "Polygon":
            continue

        x, y = geom.exterior.coords.xy
        segmentation = [list(sum(zip(x, y), ()))]

        min_x, min_y, max_x, max_y = geom.bounds
        bbox = [min_x, min_y, max_x - min_x, max_y - min_y]

        coco_dict["annotations"].append({
            "id": annotation_id,
            "image_id": img_id,
            "category_id": 1,
            "bbox": bbox,
            "area": bbox[2] * bbox[3],
            "iscrowd": 0,
            "segmentation": [segmentation[0]]
        })
        annotation_id += 1

# Save JSON
with open(output_json, 'w') as f:
    json.dump(coco_dict, f)

print("‚úÖ COCO annotations saved to:", output_json)

with open(output_json) as f:
    data = json.load(f)

print("Images:", len(data["images"]))
print("Annotations:", len(data["annotations"]))

# If not already done
!git clone https://github.com/facebookresearch/detectron2.git

from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog

# Register the dataset
register_coco_instances(
    "buildings_paris",
    {},
    "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json",  # ‚Üê your COCO-style annotations
    "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"  # ‚Üê image folder (JPGs)
)

# ‚úÖ Fix missing labels to prevent IndexError
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]

from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
import os

# Paths
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
images_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"

# 1. Register dataset
# Clear any previous registration (avoids conflicting paths)
from detectron2.data import DatasetCatalog, MetadataCatalog

if "buildings_paris" in DatasetCatalog.list():
    DatasetCatalog.remove("buildings_paris")
    MetadataCatalog.remove("buildings_paris")

# Now register again safely
register_coco_instances("buildings_paris", {}, json_path, images_path)


# 2. Config setup
cfg = get_cfg()
cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.DATASETS.TRAIN = ("buildings_paris",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.OUTPUT_DIR = output_dir
cfg.MODEL.WEIGHTS = "detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl"
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 3000
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # building

os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

# 3. Train
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

trainer = DefaultTrainer(cfg)
trainer.train()

cfg.OUTPUT_DIR = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"

with open("/content/drive/MyDrive/projects/mask_rcnn_paris/output/config.yaml", "w") as f:
    f.write(cfg.dump())

import os

image_path = '/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/AOI_3_Paris_img1017.jpg'
print("Exists?", os.path.exists(image_path))

import os
from glob import glob

jpg_folder = '/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images'
sample_files = sorted(glob(jpg_folder + '/*.jpg'))

print("Total JPGs found:", len(sample_files))
print("Sample file names:", sample_files[:5])  # Print first 5

import cv2
import matplotlib.pyplot as plt
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

# Load image
test_image = sample_files[0]  # already fetched from the folder
im = cv2.imread(test_image)

# Run inference
outputs = predictor(im)

# Visualize results
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get("buildings_paris"), scale=1.0)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

# Show image
plt.figure(figsize=(12, 12))
plt.imshow(out.get_image()[:, :, ::-1])
plt.axis("off")
plt.title("Mask R-CNN Building Footprints")
plt.show()

# Save result
output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/maskrcnn_prediction.jpg"
cv2.imwrite(output_path, out.get_image()[:, :, ::-1])
print("‚úÖ Segmented image saved at:", output_path)

from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog

# Register the dataset
register_coco_instances(
    "buildings_paris",
    {},
    "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json",  # ‚Üê your COCO-style annotations
    "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"  # ‚Üê image folder (JPGs)
)

# ‚úÖ Fix missing labels to prevent IndexError
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]

import os
import cv2
import torch
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
from detectron2.data import MetadataCatalog
from detectron2.utils.visualizer import Visualizer
from tqdm import tqdm

# Path setup
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_folder = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"
model_weights_path = os.path.join(output_folder, "model_final.pth")

# ‚úÖ Load configuration
cfg = get_cfg()
cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
cfg.MODEL.WEIGHTS = model_weights_path  # ‚úÖ FIXED PATH

# Create predictor
predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get("buildings_paris")

# Get all test images
image_paths = sorted([
    os.path.join(image_folder, fname)
    for fname in os.listdir(image_folder)
    if fname.lower().endswith(".jpg")
])

print(f"Total JPGs found: {len(image_paths)}")

# Create output folder
os.makedirs(output_folder, exist_ok=True)

# üîÅ Run inference on all images
for img_path in tqdm(image_paths):
    im = cv2.imread(img_path)
    if im is None:
        print(f"‚ö†Ô∏è Skipping unreadable image: {img_path}")
        continue

    outputs = predictor(im)
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    vis = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    # Save output
    out_path = os.path.join(output_folder, f"maskrcnn_{os.path.basename(img_path)}")
    cv2.imwrite(out_path, vis.get_image()[:, :, ::-1])

print("‚úÖ Inference complete. Segmented images saved to:", output_folder)

from detectron2.data import MetadataCatalog

# üî• FIX: Set the class label explicitly
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]

metadata = MetadataCatalog.get("buildings_paris")

from detectron2.utils.visualizer import Visualizer
import cv2
import os

# Paths
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"
os.makedirs(output_dir, exist_ok=True)

# Set class name explicitly
from detectron2.data import MetadataCatalog
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# Read all jpg images
jpg_files = sorted([f for f in os.listdir(image_dir) if f.endswith(".jpg")])
print(f"Total JPGs found: {len(jpg_files)}")

# Loop through each image
for img_name in jpg_files:
    img_path = os.path.join(image_dir, img_name)
    im = cv2.imread(img_path)

    # Skip if image failed to load
    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî couldn't read image.")
        continue

    outputs = predictor(im)

    # ‚úÖ Skip if no instances are detected
    if len(outputs["instances"]) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No buildings detected.")
        continue

    # Visualize and save
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
    cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

    print(f"‚úÖ Saved segmented: {save_path}")

outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
if len(outputs["instances"]) == 0:
    print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No buildings detected.")
      continue  # This is incorrectly indented
v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
if len(outputs["instances"]) == 0:
    print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No buildings detected.")
    continue  # Fixed indentation

v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

import os
import cv2
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
from tqdm import tqdm

# === CONFIG ===
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/batch_predictions"
os.makedirs(output_dir, exist_ok=True)

# === Metadata with correct class labels ===
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# === Initialize Predictor (after training is done) ===
from detectron2.config import get_cfg
cfg = get_cfg()
cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/model_final.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
predictor = DefaultPredictor(cfg)

# === Get list of images ===
image_list = sorted([
    os.path.join(image_dir, f)
    for f in os.listdir(image_dir)
    if f.lower().endswith(".jpg")
])
print("Total JPGs found:", len(image_list))

# === Run prediction + save ===
for img_path in tqdm(image_list):
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ùå Failed to read: {img_path}")
        continue

    outputs = predictor(im)
    instances = outputs["instances"].to("cpu")

    # ‚úÖ Skip if no valid predictions
    if len(instances) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No instances found.")
        continue

    # ‚úÖ Skip if class IDs aren't in metadata
    valid_classes = [i for i in instances.pred_classes if i.item() < len(metadata.thing_classes)]
    if len(valid_classes) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî Detected classes not in metadata.")
        continue

    # ‚úÖ Visualize
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = v.draw_instance_predictions(instances)

    # ‚úÖ Save prediction
    save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
    cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

print("‚úÖ Batch predictions complete. All images saved in:", output_dir)

MetadataCatalog.get("buildings_paris").thing_classes = ["building"]

outputs = predictor(im)

import os
print(os.listdir("/content/drive/MyDrive/projects/mask_rcnn_paris/output"))

from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog
from pycocotools.coco import COCO

# Dataset registration
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

register_coco_instances("buildings_paris", {}, json_path, image_path)

# Load categories dynamically from JSON
coco = COCO(json_path)
cats = coco.loadCats(coco.getCatIds())
thing_classes = [cat["name"] for cat in cats]
MetadataCatalog.get("buildings_paris").thing_classes = thing_classes

# RUN THIS IN A CODE CELL FIRST
!pip install -U torch torchvision
!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html

# STEP 2: Register dataset and set config
from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
import os

# Paths
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output"
model_path = os.path.join(output_dir, "model_final.pth")

# Register
register_coco_instances("buildings_paris", {}, json_path, image_dir)
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# Config
cfg = get_cfg()
cfg.merge_from_file("detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.WEIGHTS = model_path
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

predictor = DefaultPredictor(cfg)

# STEP 3: Batch predict and save results
import cv2
from tqdm import tqdm
from detectron2.utils.visualizer import Visualizer
import json
import pandas as pd
import numpy as np

batch_output_dir = os.path.join(output_dir, "batch_predictions")
os.makedirs(batch_output_dir, exist_ok=True)

image_paths = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith(".jpg")]
output_json = []
output_csv = []

for img_path in tqdm(image_paths, desc="Running inference"):
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî image not found.")
        continue

    outputs = predictor(im)

    if len(outputs["instances"]) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No detections.")
        continue

    instances = outputs["instances"].to("cpu")
    classes = instances.pred_classes.numpy()
    scores = instances.scores.numpy()
    boxes = instances.pred_boxes.tensor.numpy()

    try:
        v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
        out = v.draw_instance_predictions(instances)
        save_path = os.path.join(batch_output_dir, f"maskrcnn_{img_name}")
        cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
    except IndexError:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî class index error.")
        continue

    for i in range(len(classes)):
        class_id = int(classes[i])
        if class_id >= len(metadata.thing_classes):
            print(f"‚ö†Ô∏è Invalid class index {class_id} in {img_name}")
            continue
        label = metadata.thing_classes[class_id]
        box = boxes[i].tolist()
        output_json.append({
            "image": img_name,
            "class": label,
            "score": float(scores[i]),
            "bbox": box
        })
        output_csv.append([img_name, label, float(scores[i]), *box])

# Save JSON/CSV
json_path = os.path.join(output_dir, "predictions.json")
csv_path = os.path.join(output_dir, "predictions.csv")

with open(json_path, "w") as f:
    json.dump(output_json, f, indent=2)

pd.DataFrame(output_csv, columns=["image", "class", "score", "x1", "y1", "x2", "y2"]).to_csv(csv_path, index=False)
print("‚úÖ Export complete! JSON and CSV saved.")

import pandas as pd

csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"

# Load CSV
df = pd.read_csv(csv_path)

# Show basic info
print("‚úÖ CSV Columns:", df.columns.tolist())
print("‚úÖ Total predictions:", len(df))

# Preview top 5
df.head()

import json

json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json"

# Load JSON
with open(json_path, "r") as f:
    data = json.load(f)

# Check length and preview first entry
print("‚úÖ Total JSON entries:", len(data))
print("‚úÖ Sample Entry:\n", data[0] if data else "Empty")

# Class frequency from CSV
df['class'].value_counts()

import pandas as pd
import cv2
import matplotlib.pyplot as plt
import os

# File and folder paths
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

# Load CSV
df = pd.read_csv(csv_path)

# Pick any one image for visualization
sample_image = df['image'].iloc[0]
image_path = os.path.join(image_folder, sample_image)

# Load image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"Image not found: {image_path}")

# Draw predictions
sample_preds = df[df['image'] == sample_image]

for _, row in sample_preds.iterrows():
    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
    label = f"{row['class']} ({row['score']:.2f})"
    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

# Convert BGR to RGB for display
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Show image
plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.title(f"Predictions: {sample_image}")
plt.axis('off')
plt.show()

import json
import cv2
import matplotlib.pyplot as plt
import os

json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

# Load JSON
with open(json_path, "r") as f:
    data = json.load(f)

# Choose one image prediction
sample = data[0]
image_path = os.path.join(image_folder, sample['image'])

# Load image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"Image not found: {image_path}")

# Draw the bounding box
bbox = list(map(int, sample["bbox"]))
label = f"{sample['class']} ({sample['score']:.2f})"
cv2.rectangle(image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
cv2.putText(image, label, (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

# Display
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.imshow(image)
plt.axis('off')
plt.title(f"Prediction: {sample['image']}")
plt.show()

import pandas as pd
import cv2
import matplotlib.pyplot as plt

# Paths
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"

# Load predictions
df = pd.read_csv(csv_path)
print("‚úÖ Total predictions:", len(df))

# Preview 1 image
sample = df.iloc[0]
img_name = sample['image']
img_path = f"{image_folder}/{img_name}"

# Read image
image = cv2.imread(img_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Draw all predictions for this image
image_df = df[df['image'] == img_name]

for _, row in image_df.iterrows():
    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
    label = f"{row['class']} ({row['score']:.2f})"
    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)

# Show
plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.title(f"Prediction: {img_name}")
plt.axis("off")
plt.show()

import json

json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json"

# Load
with open(json_path, "r") as f:
    data = json.load(f)

print("‚úÖ Total JSON Predictions:", len(data))

# Visualize 1 sample
sample = data[0]
img_name = sample['image']
img_path = f"{image_folder}/{img_name}"

image = cv2.imread(img_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Draw all detections from this image
for det in [d for d in data if d["image"] == img_name]:
    x1, y1, x2, y2 = map(int, det["bbox"])
    label = f'{det["class"]} ({det["score"]:.2f})'
    cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)
    cv2.putText(image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)

plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.title(f"Predictions: {img_name}")
plt.axis("off")
plt.show()

from detectron2.utils.visualizer import Visualizer
from detectron2.engine.defaults import DefaultPredictor
import os
import cv2

# Set threshold and output path
CONF_THRESH = 0.5
save_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
os.makedirs(save_dir, exist_ok=True)

# Loop through predictions (CSV-based loop or direct inference)
for img_path in image_paths:  # Make sure image_paths is a valid list
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)
    if im is None:
        continue

    outputs = predictor(im)
    instances = outputs["instances"].to("cpu")

    if len(instances) == 0:
        continue

    # Apply confidence filter
    conf_mask = instances.scores > CONF_THRESH
    filtered_instances = instances[conf_mask]

    if len(filtered_instances) == 0:
        continue

    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = v.draw_instance_predictions(filtered_instances)

    # Save the image
    out_path = os.path.join(save_dir, f"seg_{img_name}")
    cv2.imwrite(out_path, out.get_image()[:, :, ::-1])

import os
import cv2
from detectron2.engine import DefaultPredictor
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog
from detectron2.config import get_cfg
from tqdm import tqdm

# === CONFIG ===
CONF_THRESH = 0.3  # adjust as needed (was 0.5)
save_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
os.makedirs(save_dir, exist_ok=True)

# === LOAD MODEL ===
cfg = get_cfg()
cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = CONF_THRESH
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # assuming only 'building'
cfg.MODEL.DEVICE = "cuda"  # or "cpu"
cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/model_final.pth"

predictor = DefaultPredictor(cfg)

# === REGISTER METADATA ===
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# === LOAD IMAGES ===
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(".jpg")]

print(f"üîç Found {len(image_paths)} images")

# === INFERENCE LOOP ===
for img_path in tqdm(image_paths, desc="Processing images"):
    img_name = os.path.basename(img_path)
    print(f"\nüñºÔ∏è Processing: {img_name}")

    im = cv2.imread(img_path)
    if im is None:
        print("‚ö†Ô∏è Image not found, skipping.")
        continue

    outputs = predictor(im)
    instances = outputs["instances"].to("cpu")

    if len(instances) == 0:
        print("‚ö†Ô∏è No detections found.")
        continue

    conf_mask = instances.scores > CONF_THRESH
    filtered_instances = instances[conf_mask]

    if len(filtered_instances) == 0:
        print("‚ö†Ô∏è No detections above confidence threshold.")
        continue

    # ‚úÖ Save visualization
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    vis_output = v.draw_instance_predictions(filtered_instances)
    out_path = os.path.join(save_dir, f"seg_{img_name}")
    cv2.imwrite(out_path, vis_output.get_image()[:, :, ::-1])
    print(f"‚úÖ Saved: {out_path}")

'/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks'

import os
import cv2
import matplotlib.pyplot as plt

# Path to your output visual masks
visual_mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"

# Get list of saved visual mask files
image_files = [f for f in os.listdir(visual_mask_dir) if f.lower().endswith((".jpg", ".png"))]

# Check how many files exist
print(f"üì∏ Total visual mask outputs: {len(image_files)}")

# Display the first one as a test
if image_files:
    sample_path = os.path.join(visual_mask_dir, image_files[0])
    print("üñºÔ∏è Showing sample file:", sample_path)

    # Load image
    image = cv2.imread(sample_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Show with matplotlib
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    plt.axis("off")
    plt.title(f"Sample Output: {image_files[0]}")
    plt.show()
else:
    print("‚ö†Ô∏è No visual predictions found in the folder.")

import os
import cv2
import matplotlib.pyplot as plt

# ‚úÖ Correct paths
visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

# Get all visuals
visual_files = [f for f in os.listdir(visual_dir) if f.endswith(".jpg")]
print(f"üñºÔ∏è Found {len(visual_files)} visual predictions.")

# Show one sample
if not visual_files:
    print("‚ö†Ô∏è No visual images found.")
else:
    sample_file = visual_files[0]  # or choose another
    base_name = sample_file.replace("seg_", "").replace(".jpg", "")

    visual_path = os.path.join(visual_dir, sample_file)
    mask_path = os.path.join(mask_dir, f"{base_name}_mask.png")

    visual_img = cv2.imread(visual_path)
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if visual_img is None or mask_img is None:
        print("‚ö†Ô∏è One of the images could not be loaded.")
    else:
        visual_img = cv2.cvtColor(visual_img, cv2.COLOR_BGR2RGB)

        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.imshow(visual_img)
        plt.title("üéØ Visual Prediction")
        plt.axis("off")

        plt.subplot(1, 2, 2)
        plt.imshow(mask_img, cmap='gray')
        plt.title("üß± Binary GIS Mask")
        plt.axis("off")

        plt.suptitle(f"Sample: {base_name}", fontsize=14)
        plt.tight_layout()
        plt.show()

import os
import cv2
import matplotlib.pyplot as plt

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

visual_files = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])
print(f"üñºÔ∏è Found {len(visual_files)} visual predictions.")

# ‚úÖ Loop until we find a working pair
for sample_file in visual_files:
    base_name = sample_file.replace("seg_", "").replace(".jpg", "")
    visual_path = os.path.join(visual_dir, sample_file)
    mask_path = os.path.join(mask_dir, f"{base_name}_mask.png")

    visual_img = cv2.imread(visual_path)
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if visual_img is not None and mask_img is not None:
        visual_img = cv2.cvtColor(visual_img, cv2.COLOR_BGR2RGB)

        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.imshow(visual_img)
        plt.title("üéØ Visual Prediction")
        plt.axis("off")

        plt.subplot(1, 2, 2)
        plt.imshow(mask_img, cmap='gray')
        plt.title("üß± Binary GIS Mask")
        plt.axis("off")

        plt.suptitle(f"Sample: {base_name}", fontsize=14)
        plt.tight_layout()
        plt.show()
        break
else:
    print("‚ö†Ô∏è No valid visual + mask pair found.")

import os
import cv2
import numpy as np
from detectron2.engine import DefaultPredictor
from tqdm import tqdm

# Paths
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"
os.makedirs(output_dir, exist_ok=True)

# Confidence threshold
CONF_THRESH = 0.5
predictor.model.eval()

# Get all image paths
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(".jpg")]

print(f"üîç Found {len(image_paths)} images.")
skipped = 0

for img_path in tqdm(image_paths, desc="Saving binary masks"):
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} (image not found)")
        skipped += 1
        continue

    outputs = predictor(im)
    instances = outputs["instances"].to("cpu")

    # Filter by score
    conf_mask = instances.scores > CONF_THRESH
    filtered = instances[conf_mask]

    if len(filtered) == 0:
        skipped += 1
        continue

    # Combine all masks into one binary mask
    full_mask = np.zeros(im.shape[:2], dtype=np.uint8)
    for mask in filtered.pred_masks:
        full_mask = np.logical_or(full_mask, mask.numpy())

    # Save binary mask
    save_path = os.path.join(output_dir, img_name.replace(".jpg", ".png"))
    cv2.imwrite(save_path, (full_mask * 255).astype(np.uint8))

print(f"‚úÖ Done. Skipped: {skipped}, Saved: {len(image_paths) - skipped}")

import os
import cv2
import matplotlib.pyplot as plt

# Define paths
visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

# Sample 5 matching visuals + masks
visual_sample = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])[:5]
mask_sample = [f.replace(".jpg", ".png") for f in visual_sample]

print(f"üß† Previewing {len(visual_sample)} pairs")

# Plot each pair
for vis_file, mask_file in zip(visual_sample, mask_sample):
    vis_path = os.path.join(visual_dir, vis_file)
    mask_path = os.path.join(mask_dir, mask_file)

    # Load images
    vis_img = cv2.imread(vis_path)
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if vis_img is None or mask_img is None:
        print(f"‚ö†Ô∏è Skipping pair (cannot read): {vis_file}")
        continue

    vis_img = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)

    # Plot side-by-side
    plt.figure(figsize=(10, 5))
    plt.suptitle(f"üñºÔ∏è {vis_file}", fontsize=14)

    plt.subplot(1, 2, 1)
    plt.title("Visual Prediction")
    plt.imshow(vis_img)
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.title("Binary Mask")
    plt.imshow(mask_img, cmap="gray")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

import os
import cv2

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"

# Get all image files
image_files = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])

# Try reading and log the bad ones
unreadable = []

for f in image_files[:20]:  # check first 20 for now
    path = os.path.join(visual_dir, f)
    img = cv2.imread(path)
    if img is None:
        unreadable.append(f)

print(f"‚ùå Unreadable Images: {len(unreadable)}")
for name in unreadable:
    print("üî∏", name)

import os

mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"
mask_files = sorted(os.listdir(mask_dir))

# Check for matching .png masks
matches = [f for f in mask_files if f.startswith("seg_RGB-PanSharpen_AOI_3_Paris_img10") and f.endswith(".png")]

print(f"üß© Matching PNG masks for 'img10': {matches if matches else '‚ùå Not found'}")

import cv2
import os
import matplotlib.pyplot as plt

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

# Filter matched pairs
visual_files = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])
mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(".png")])

matched = []
for v in visual_files:
    mask_name = v.replace(".jpg", ".png")  # Assuming same prefix
    if mask_name in mask_files:
        matched.append((v, mask_name))

print(f"‚úÖ Matched pairs: {len(matched)}")

# Show a few samples
for vis_file, mask_file in matched[:5]:
    vis_path = os.path.join(visual_dir, vis_file)
    mask_path = os.path.join(mask_dir, mask_file)

    vis = cv2.imread(vis_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if vis is None or mask is None:
        print(f"‚ö†Ô∏è Could not read: {vis_file} or {mask_file}")
        continue

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))
    plt.title(f"Visual: {vis_file}")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask, cmap='gray')
    plt.title(f"Binary Mask: {mask_file}")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

import os
import cv2
import matplotlib.pyplot as plt

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

# Utility: extract image id like img1057
def extract_id(filename):
    parts = filename.split("_")
    for part in parts:
        if part.startswith("img"):
            return part.split(".")[0]  # e.g., img1057
    return None

# Index files by ID
visual_map = {extract_id(f): f for f in os.listdir(visual_dir) if f.endswith(".jpg")}
mask_map = {extract_id(f): f for f in os.listdir(mask_dir) if f.endswith(".png")}

# Match
matched = [(visual_map[k], mask_map[k]) for k in visual_map.keys() if k in mask_map]

print(f"‚úÖ Matched pairs: {len(matched)}")

# Preview
for vis_file, mask_file in matched[:5]:
    vis_path = os.path.join(visual_dir, vis_file)
    mask_path = os.path.join(mask_dir, mask_file)

    vis = cv2.imread(vis_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if vis is None or mask is None:
        print(f"‚ö†Ô∏è Could not read: {vis_file} or {mask_file}")
        continue

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))
    plt.title(f"Visual: {vis_file}")
    plt.axis("off")

    plt.subplot(1, 2, 2)
    plt.imshow(mask, cmap="gray")
    plt.title(f"Binary Mask: {mask_file}")
    plt.axis("off")

    plt.tight_layout()
    plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# === Paths ===
image_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks/seg_RGB-PanSharpen_AOI_3_Paris_img1396.jpg"
mask_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks/RGB-PanSharpen_AOI_3_Paris_img1396.png"

# === Load image and mask ===
image = cv2.imread(image_path)
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

# Resize mask to match image size
mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)

# Convert BGR to RGB
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# === Create red overlay for mask ===
mask_colored = np.zeros_like(image_rgb)
mask_colored[mask_resized > 0] = [255, 0, 0]  # Red

# === Blend mask on top of original image ===
blended = cv2.addWeighted(image_rgb, 0.8, mask_colored, 0.5, 0)

# === Show original and overlay side-by-side ===
plt.figure(figsize=(16, 6))
plt.subplot(1, 2, 1)
plt.imshow(image_rgb)
plt.title("Original Image")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(blended)
plt.title("Overlay: Mask on Image")
plt.axis("off")

plt.tight_layout()
plt.show()

print("Unique mask values:", np.unique(mask_resized))  # should print [0] if empty

!ls "/content/drive/MyDrive/projects/mask_rcnn_paris/output"

import os
import cv2
import numpy as np
from tqdm import tqdm

# üìÇ Directories
visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"
overlay_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/overlays"
os.makedirs(overlay_dir, exist_ok=True)

# üì∏ Get matching pairs
visual_files = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])
mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(".png")])

# üîÑ Match base names
matched_pairs = []
for vis_file in visual_files:
    base_name = vis_file.replace("seg_", "").replace(".jpg", "")
    mask_file = f"{base_name}.png"
    if mask_file in mask_files:
        matched_pairs.append((vis_file, mask_file))

print(f"‚úÖ Matched overlays: {len(matched_pairs)}")

# üé® Generate overlays
for vis_file, mask_file in tqdm(matched_pairs, desc="Saving overlays"):
    vis_path = os.path.join(visual_dir, vis_file)
    mask_path = os.path.join(mask_dir, mask_file)

    image = cv2.imread(vis_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if image is None or mask is None:
        continue

    # üîé Skip empty masks
    if np.count_nonzero(mask) == 0:
        continue

    # ‚úÖ Resize if shape mismatch
    if mask.shape != image.shape[:2]:
        mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)

    # üî¥ Create red overlay
    red_mask = np.zeros_like(image)
    red_mask[mask > 0] = [0, 0, 255]  # Red

    # üß† Blend overlay
    overlay = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)

    # üíæ Save
    out_path = os.path.join(overlay_dir, f"overlay_{mask_file}")
    cv2.imwrite(out_path, overlay)

print("‚úÖ All overlays saved to:", overlay_dir)

import os

overlay_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/overlays"

# List and sort overlay files
overlay_files = sorted([f for f in os.listdir(overlay_dir) if f.endswith(".png")])

# Show a sample
print("üßæ Sample overlay filenames:")
for name in overlay_files[:10]:
    print("  ‚úÖ", name)

import os

overlay_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/overlays"

# Sanity check ‚Äî does the directory exist?
print("üìÇ Overlay directory exists:", os.path.exists(overlay_dir))

# List all files (not just .png)
all_files = os.listdir(overlay_dir)
print(f"üì¶ Total files found: {len(all_files)}")

# Filter for PNGs
overlay_files = sorted([f for f in all_files if f.endswith(".png")])
print(f"üßæ Found {len(overlay_files)} .png files")

# Show samples
print("üìú Sample overlay filenames:")
for name in overlay_files[:10]:
    print("   ‚úÖ", name)

import cv2
import numpy as np
import os
from tqdm import tqdm

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"
save_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/overlays"
os.makedirs(save_dir, exist_ok=True)

# List and match files
visual_files = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])
mask_files = sorted([f for f in os.listdir(mask_dir) if f.endswith(".png")])

matched_pairs = []
for vis_name in visual_files:
    base = vis_name.replace("seg_", "").replace(".jpg", "")
    mask_name = f"{base}.png"
    if mask_name in mask_files:
        matched_pairs.append((vis_name, mask_name))

print(f"‚úÖ Matched overlays: {len(matched_pairs)}")

# Save overlays
for vis_name, mask_name in tqdm(matched_pairs, desc="Saving overlays"):
    vis_path = os.path.join(visual_dir, vis_name)
    mask_path = os.path.join(mask_dir, mask_name)

    vis_img = cv2.imread(vis_path)
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if vis_img is None or mask_img is None:
        continue

    # Resize mask if needed
    if mask_img.shape != vis_img.shape[:2]:
        mask_img = cv2.resize(mask_img, (vis_img.shape[1], vis_img.shape[0]), interpolation=cv2.INTER_NEAREST)

    # Colored mask (red)
    color_mask = np.zeros_like(vis_img)
    color_mask[mask_img > 0] = [0, 0, 255]  # Red

    # Overlay with 60% visual and 40% mask
    overlay = cv2.addWeighted(vis_img, 0.6, color_mask, 0.4, 0)

    # Save with consistent naming
    filename = f"overlay_{mask_name.replace('.png', '')}.png"
    cv2.imwrite(os.path.join(save_dir, filename), overlay)

print(f"‚úÖ All overlays saved to: {save_dir}")

print(sorted(os.listdir(save_dir))[:5])

from google.colab import drive
drive.mount('/content/drive')

# Now list your project folder
!ls "/content/drive/MyDrive/projects/mask_rcnn_paris/output"

!find /content/drive/MyDrive/projects/mask_rcnn_paris/ -name "*.csv"

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ‚úÖ Load CSV
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(csv_path)

# ‚úÖ Check columns
print("üìä Columns:", df.columns.tolist())
print("üìà Total predictions:", len(df))

# ‚úÖ Filter out low confidence if needed
CONF_THRESH = 0.5
df = df[df['score'] >= CONF_THRESH]

# ‚úÖ Calculate center point (approx hotspot location)
df['x_center'] = (df['x1'] + df['x2']) / 2
df['y_center'] = (df['y1'] + df['y2']) / 2

# ‚úÖ Create heatmap plot
plt.figure(figsize=(10, 8))
sns.kdeplot(
    x=df["x_center"],
    y=df["y_center"],
    cmap="Reds",
    fill=True,
    thresh=0.05,
    bw_adjust=1
)
plt.title("üî• Predictive Hotspot Heatmap (Construction Detection)")
plt.xlabel("X center")
plt.ylabel("Y center")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# === Load Data ===
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(csv_path)

# === Filter High-Confidence Predictions ===
CONF_THRESH = 0.5
df = df[df['score'] >= CONF_THRESH]

# === Compute Center Points ===
df['x_center'] = (df['x1'] + df['x2']) / 2
df['y_center'] = (df['y1'] + df['y2']) / 2

# === Heatmap ===
plt.figure(figsize=(12, 8))
ax = sns.kdeplot(
    x=df["x_center"],
    y=df["y_center"],
    cmap="YlOrRd",         # üî¥ Red-yellow gradient
    fill=True,
    thresh=0.01,
    bw_adjust=1.2,
    levels=100
)

# === Aesthetics ===
plt.title("üö® Predictive Heatmap: High-Risk Construction Zones")
plt.xlabel("Image X Center (pixels)")
plt.ylabel("Image Y Center (pixels)")
plt.grid(True)

# === Add Color Legend ===
mappable = ax.collections[0]
plt.colorbar(mappable, ax=ax, label="Risk Intensity")

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

# === Load predictions ===
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(csv_path)

# === Filter for confidence threshold ===
CONF_THRESH = 0.5
df = df[df["score"] >= CONF_THRESH]

# === Compute centers of predicted boxes ===
df["x_center"] = (df["x1"] + df["x2"]) / 2
df["y_center"] = (df["y1"] + df["y2"]) / 2

# === Get image boundary for box ===
x_min, x_max = df["x_center"].min(), df["x_center"].max()
y_min, y_max = df["y_center"].min(), df["y_center"].max()

# === Plot heatmap ===
plt.figure(figsize=(14, 10))
ax = sns.kdeplot(
    x=df["x_center"],
    y=df["y_center"],
    cmap="YlOrRd",     # Red-yellow map
    fill=True,
    bw_adjust=1.1,
    thresh=0.02,
    levels=100
)

# === Plot clustering points on top ===
plt.scatter(df["x_center"], df["y_center"], color="black", alpha=0.02, s=10, label="Predicted Centers")

# === Add rectangle for image boundary ===
plt.plot(
    [x_min, x_max, x_max, x_min, x_min],
    [y_min, y_min, y_max, y_max, y_min],
    linestyle="--", color="blue", label="Prediction Bounds"
)

# === Styling ===
plt.title("üî• Predictive Heatmap with Image Boundary")
plt.xlabel("X Coordinate (image space)")
plt.ylabel("Y Coordinate (image space)")
plt.legend()
plt.colorbar(ax.collections[0], label="Prediction Density")
plt.grid(True)

# === Save heatmap as image ===
output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictive_heatmap.png"
plt.savefig(output_path, dpi=300, bbox_inches="tight")
print(f"‚úÖ Heatmap saved to: {output_path}")

plt.tight_layout()
plt.show()

import os

csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
print("‚úÖ File Exists:", os.path.exists(csv_path))

import pandas as pd

# Corrected path (ensure this exists exactly)
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"

# Try loading it
df = pd.read_csv(csv_path)
print("‚úÖ CSV Loaded Successfully")
df.head()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load predictions
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(csv_path)

# Midpoints of bounding boxes
df['x_center'] = (df['x1'] + df['x2']) / 2
df['y_center'] = (df['y1'] + df['y2']) / 2

# Start the figure
plt.figure(figsize=(12, 10))

# ‚úÖ Capture the kdeplot as a QuadContourSet object
kde_plot = sns.kdeplot(
    x=df['x_center'],
    y=df['y_center'],
    weights=df['score'],
    cmap="YlOrRd",
    fill=True,
    bw_adjust=0.8,
    thresh=0.05,
    levels=100
)

# Labels and title
plt.title("Predictive Heatmap of Detected Buildings", fontsize=16)
plt.xlabel("X (image space)")
plt.ylabel("Y (image space)")
plt.grid(True)

# ‚úÖ Add colorbar based on the last mappable object
plt.colorbar(kde_plot.collections[0], label="Density / Risk")

# Save and show
heatmap_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/heatmap_predictions.png"
plt.savefig(heatmap_path, dpi=300)
plt.show()

print("‚úÖ Heatmap saved to:", heatmap_path)

import os
print("‚úÖ File Exists:", os.path.exists("/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"))

!find /content/drive/MyDrive/projects/mask_rcnn_paris/ -name "*.csv"

!pip install fiona geopandas shapely --quiet

"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/summaryData/"

import os

summary_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/summaryData"
files = os.listdir(summary_path)

for f in files:
    print(f)

import pandas as pd
from shapely import wkt
from shapely.geometry import Polygon, mapping
import fiona

# Load the metadata CSV file
metadata_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/summaryData/AOI_3_Paris_Train_Building_Solutions.csv"
metadata_df = pd.read_csv(metadata_path)

# Filter metadata for the selected image
selected_image_id = "AOI_3_Paris_img485"
image_data = metadata_df[metadata_df['ImageId'] == selected_image_id]

# Convert WKT Geo column to Shapely polygons
geo_polygons = image_data['PolygonWKT_Geo'].dropna().apply(wkt.loads)

# Compute total bounding box
combined_bounds = geo_polygons.iloc[0].bounds
for poly in geo_polygons.iloc[1:]:
    combined_bounds = (
        min(combined_bounds[0], poly.bounds[0]),
        min(combined_bounds[1], poly.bounds[1]),
        max(combined_bounds[2], poly.bounds[2]),
        max(combined_bounds[3], poly.bounds[3]),
    )

min_lon, min_lat, max_lon, max_lat = combined_bounds
mid_lat = min_lat + (max_lat - min_lat) * 0.6  # 60% for zoning

# Create red and yellow polygons
red_zone_polygon = Polygon([
    (min_lon, mid_lat),
    (max_lon, mid_lat),
    (max_lon, max_lat),
    (min_lon, max_lat),
])

yellow_zone_polygon = Polygon([
    (min_lon, min_lat),
    (max_lon, min_lat),
    (max_lon, mid_lat),
    (min_lon, mid_lat),
])

# Save as GeoJSON
schema = {'geometry': 'Polygon', 'properties': {'zone': 'str'}}
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"

with fiona.open(red_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as red_file:
    red_file.write({'geometry': mapping(red_zone_polygon), 'properties': {'zone': 'red'}})

with fiona.open(yellow_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as yellow_file:
    yellow_file.write({'geometry': mapping(yellow_zone_polygon), 'properties': {'zone': 'yellow'}})

import pandas as pd
from shapely import wkt
from shapely.geometry import Polygon, mapping
import fiona

# Step 1: Load the metadata CSV file
metadata_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/summaryData/AOI_3_Paris_Train_Building_Solutions.csv"
metadata_df = pd.read_csv(metadata_path)

#metadata_df = pd.read_csv('AOI_3_Paris_Train_Building_Solutions.csv')

# Step 2: Filter metadata for the selected image
selected_image_id = "AOI_3_Paris_img485"
image_data = metadata_df[metadata_df['ImageId'] == selected_image_id]

# Step 3: Convert WKT Geo column to Shapely polygons
geo_polygons = image_data['PolygonWKT_Geo'].dropna().apply(wkt.loads)

# Step 4: Compute the total bounding box of the image area
combined_bounds = geo_polygons.iloc[0].bounds
for poly in geo_polygons.iloc[1:]:
    combined_bounds = (
        min(combined_bounds[0], poly.bounds[0]),
        min(combined_bounds[1], poly.bounds[1]),
        max(combined_bounds[2], poly.bounds[2]),
        max(combined_bounds[3], poly.bounds[3]),
    )

min_lon, min_lat, max_lon, max_lat = combined_bounds
mid_lat = min_lat + (max_lat - min_lat) * 0.6  # 60% lower = yellow

# Step 5: Create zoning polygons
red_zone_polygon = Polygon([
    (min_lon, mid_lat),
    (max_lon, mid_lat),
    (max_lon, max_lat),
    (min_lon, max_lat),
])

yellow_zone_polygon = Polygon([
    (min_lon, min_lat),
    (max_lon, min_lat),
    (max_lon, mid_lat),
    (min_lon, mid_lat),
])

# Step 6: Save zones as GeoJSON files
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"

schema = {'geometry': 'Polygon', 'properties': {'zone': 'str'}}

with fiona.open(red_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as red_file:
    red_file.write({
        'geometry': mapping(red_zone_polygon),
        'properties': {'zone': 'red'}
    })

with fiona.open(yellow_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as yellow_file:
    yellow_file.write({
        'geometry': mapping(yellow_zone_polygon),
        'properties': {'zone': 'yellow'}
    })

(red_zone_path, yellow_zone_path)

from google.colab import files

# Download red zone
files.download('/content/red_zone_real.geojson')

# Download yellow zone
files.download('/content/yellow_zone_real.geojson')

import pandas as pd
from shapely import wkt
from shapely.geometry import Polygon, mapping
import fiona

# Load the metadata CSV from your Drive
metadata_df = pd.read_csv("/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/summaryData/AOI_3_Paris_Train_Building_Solutions.csv")

# Select the target image
selected_image_id = "AOI_3_Paris_img485"
image_data = metadata_df[metadata_df['ImageId'] == selected_image_id]

# Convert WKT polygons to Shapely geometry
geo_polygons = image_data['PolygonWKT_Geo'].dropna().apply(wkt.loads)

# Compute bounding box for the image's full building area
combined_bounds = geo_polygons.iloc[0].bounds
for poly in geo_polygons.iloc[1:]:
    combined_bounds = (
        min(combined_bounds[0], poly.bounds[0]),
        min(combined_bounds[1], poly.bounds[1]),
        max(combined_bounds[2], poly.bounds[2]),
        max(combined_bounds[3], poly.bounds[3]),
    )

min_lon, min_lat, max_lon, max_lat = combined_bounds
mid_lat = min_lat + (max_lat - min_lat) * 0.6

# Define zoning polygons
red_zone_polygon = Polygon([
    (min_lon, mid_lat), (max_lon, mid_lat),
    (max_lon, max_lat), (min_lon, max_lat)
])

yellow_zone_polygon = Polygon([
    (min_lon, min_lat), (max_lon, min_lat),
    (max_lon, mid_lat), (min_lon, mid_lat)
])

# Save as GeoJSON in /content/
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"

schema = {'geometry': 'Polygon', 'properties': {'zone': 'str'}}

with fiona.open(red_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as red_file:
    red_file.write({
        'geometry': mapping(red_zone_polygon),
        'properties': {'zone': 'red'}
    })

with fiona.open(yellow_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as yellow_file:
    yellow_file.write({
        'geometry': mapping(yellow_zone_polygon),
        'properties': {'zone': 'yellow'}
    })

print("‚úÖ Zoning polygons regenerated and saved.")

!pip install fpdf

import os
jpg_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
os.listdir(jpg_folder)

image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/RGB-PanSharpen_AOI_3_Paris_img485.jpg"

image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/RGB-PanSharpen_AOI_3_Paris_img485.jpg"

import os

jpg_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
for file in os.listdir(jpg_folder):
    print(file)

image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/<correct_filename>"

import pandas as pd

df = pd.read_csv("/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv")
print(df.columns.tolist())
df.head()

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF

# ‚úÖ CONFIGURATION
image_filename = "RGB-PanSharpen_AOI_3_Paris_img485.jpg"
image_path = f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/{image_filename}"
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/content/overlayed_map.jpg"
report_output = "/content/classification_report.pdf"

# ‚úÖ STEP 1: Load image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"‚ùå Image not found at path: {image_path}")
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# ‚úÖ STEP 2: Load zoning files
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# ‚úÖ STEP 3: Geo-mapping setup
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ STEP 4: Load predictions
pred_df = pd.read_csv(predictions_path)
pred_df = pred_df[pred_df['image'] == image_filename]  # ‚úÖ Use correct column

# ‚úÖ STEP 5: Draw zoning overlay
zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))       # Red zone
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))  # Yellow zone

zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# ‚úÖ STEP 6: Classify and draw boxes
auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}

for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy, width, height)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ‚úÖ STEP 7: Save overlayed map
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# ‚úÖ STEP 8: Create report PDF
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")

pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section_body(f"{label}: {count} buildings")

pdf.section_title("3. Map Overview")
pdf.image(overlay_output, x=10, y=None, w=180)

pdf.output(report_output)

# ‚úÖ Final confirmation
print("‚úÖ Overlay image saved at:", overlay_output)
print("‚úÖ PDF report saved at:", report_output)

df = pd.read_csv("/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv")
print(df['image'].unique())

filtered = df[df['image'] == 'RGB-PanSharpen_AOI_3_Paris_img485.jpg']
print(len(filtered))
filtered.head()

import os
import cv2
import pandas as pd
from tqdm import tqdm
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2 import model_zoo

# ‚úÖ Step 1: Setup model config
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # confidence threshold
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # for 'building' only
cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/model_final.pth"  # Your trained model path
cfg.MODEL.DEVICE = "cuda"  # or "cpu" if no GPU

predictor = DefaultPredictor(cfg)

# ‚úÖ Step 2: Define folders
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"

# ‚úÖ Step 3: Run inference on all images
results = []
for filename in tqdm(sorted(os.listdir(image_folder))):
    if not filename.lower().endswith((".jpg", ".jpeg", ".png")):
        continue

    img_path = os.path.join(image_folder, filename)
    img = cv2.imread(img_path)
    if img is None:
        continue

    outputs = predictor(img)
    boxes = outputs["instances"].pred_boxes.tensor.cpu().numpy()
    scores = outputs["instances"].scores.cpu().numpy()

    for i in range(len(boxes)):
        x1, y1, x2, y2 = boxes[i]
        results.append({
            "image": filename,
            "class": "building",
            "score": float(scores[i]),
            "x1": int(x1),
            "y1": int(y1),
            "x2": int(x2),
            "y2": int(y2)
        })

# ‚úÖ Step 4: Save to CSV
df = pd.DataFrame(results)
df.to_csv(output_csv_path, index=False)
print(f"‚úÖ Predictions saved to: {output_csv_path}")

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF

# ‚úÖ CONFIGURATION
image_filename = "RGB-PanSharpen_AOI_3_Paris_img485.jpg"  # change to any image you want to test
image_path = f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/{image_filename}"
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/content/overlayed_map.jpg"
report_output = "/content/classification_report.pdf"

# ‚úÖ STEP 1: Load image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"‚ùå Image not found at: {image_path}")
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# ‚úÖ STEP 2: Load zoning data
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# ‚úÖ STEP 3: Geo-mapping logic
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ STEP 4: Load predictions
pred_df = pd.read_csv(predictions_path)
pred_df = pred_df[pred_df['image'] == image_filename]

# ‚úÖ STEP 5: Draw zoning overlay
zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))       # Red = Unauthorized
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))  # Yellow = Authorized

zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# ‚úÖ STEP 6: Draw predictions & classify
auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}

for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy, width, height)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ‚úÖ STEP 7: Save the overlay map
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# ‚úÖ STEP 8: Create classification report PDF
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

"""pdf.section_title("1. Zoning Summary")
pdf.section_body("üî¥ Red Zone = No construction allowed\nüü° Yellow Zone = Construction allowed")"""
pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")


pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section_body(f"{label}: {count} buildings")

pdf.section_title("3. Map Overview")
pdf.image(overlay_output, x=10, y=None, w=180)

pdf.output(report_output)

print("‚úÖ Overlay Image:", overlay_output)
print("‚úÖ PDF Report:", report_output)

from google.colab import files
files.download("/content/overlayed_map.jpg")
files.download("/content/classification_report.pdf")

import os
import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF
from tqdm import tqdm
import zipfile

# ‚úÖ PATHS
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
output_dir = "/content/final_outputs"
os.makedirs(output_dir, exist_ok=True)

# ‚úÖ Load data
df = pd.read_csv(predictions_path)
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# ‚úÖ Geo bounds
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

def draw_zone(polygon, image_shape, color):
    height, width = image_shape[:2]
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    return coords

# ‚úÖ PDF Template
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

# ‚úÖ Process each image
for image_name in tqdm(df['image'].unique()):
    image_path = os.path.join(image_folder, image_name)
    if not os.path.exists(image_path):
        continue

    image = cv2.imread(image_path)
    if image is None:
        continue

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    height, width, _ = image.shape
    zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

    # Draw zones
    red_coords = draw_zone(red_zone.geometry.iloc[0], image.shape, (255, 0, 0))
    yellow_coords = draw_zone(yellow_zone.geometry.iloc[0], image.shape, (255, 255, 0))
    cv2.fillPoly(zone_overlay, red_coords, (255, 0, 0))
    cv2.fillPoly(zone_overlay, yellow_coords, (255, 255, 0))
    zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

    # Filter predictions
    image_preds = df[df['image'] == image_name]
    auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}

    for _, row in image_preds.iterrows():
        x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        lon, lat = pixel_to_latlon(cx, cy, width, height)
        point = Point(lon, lat)

        if red_zone.contains(point).any():
            label = "Unauthorized"
            color = (255, 0, 0)
        elif yellow_zone.contains(point).any():
            label = "Authorized"
            color = (0, 255, 0)
        else:
            label = "Unclassified"
            color = (255, 255, 255)

        auth_counts[label] += 1
        cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Save overlay
    base_name = os.path.splitext(image_name)[0]
    map_path = os.path.join(output_dir, f"overlayed_map_{base_name}.jpg")
    cv2.imwrite(map_path, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

    # Generate PDF
    pdf = PDF()
    pdf.add_page()
    pdf.section_title("1. Zoning Summary")
    pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")

    pdf.section_title("2. Classification Result")
    for label, count in auth_counts.items():
        pdf.section_body(f"{label}: {count} buildings")

    pdf.section_title("3. Map Overview")
    pdf.image(map_path, x=10, y=None, w=180)

    report_path = os.path.join(output_dir, f"classification_report_{base_name}.pdf")
    pdf.output(report_path)

print("‚úÖ All images processed and saved to:", output_dir)

# ‚úÖ ZIP everything
zip_path = "/content/final_output_bundle.zip"
with zipfile.ZipFile(zip_path, 'w') as zipf:
    for foldername, _, filenames in os.walk(output_dir):
        for filename in filenames:
            full_path = os.path.join(foldername, filename)
            arcname = os.path.relpath(full_path, output_dir)
            zipf.write(full_path, arcname)

print("‚úÖ Zipped output saved to:", zip_path)

from google.colab import files
files.download("/content/final_output_bundle.zip")

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
from shapely.geometry import Point
from fpdf import FPDF

# ‚úÖ CONFIG
image_filename = "RGB-PanSharpen_AOI_3_Paris_img485.jpg"
image_path = f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/{image_filename}"
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/content/overlayed_map.jpg"
heatmap_output = "/content/predictive_heatmap.jpg"
report_output = "/content/classification_report.pdf"

# ‚úÖ Load base image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"Image not found: {image_path}")
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# ‚úÖ Load GIS zones
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y):
    lon = min_lon + (x / width) * (max_lon - min_lon)
    lat = max_lat - (y / height) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ Draw zoning overlay
zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))
zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# ‚úÖ Load predictions
df = pd.read_csv(predictions_path)
pred_df = df[df['image'] == image_filename]
auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}
unauthorized_points = []

# ‚úÖ Classify and draw boxes
for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
        unauthorized_points.append((lat, lon))
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ‚úÖ Save zoning + detection overlay
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# ‚úÖ Create heatmap if unauthorized points exist
if len(unauthorized_points) > 0:
    heat_df = pd.DataFrame(unauthorized_points, columns=["lat", "lon"])
    plt.figure(figsize=(10, 8))
    sns.kdeplot(
        data=heat_df, x="lon", y="lat",
        cmap="Reds", fill=True, bw_adjust=0.3, alpha=0.8
    )
    plt.title("Predictive Unauthorized Construction Heatmap")
    plt.xlim(min_lon, max_lon)
    plt.ylim(min_lat, max_lat)
    plt.xlabel("Longitude")
    plt.ylabel("Latitude")
    plt.grid(True)
    plt.savefig(heatmap_output, dpi=300)
    plt.close()
else:
    heatmap_output = None
    print("‚ö†Ô∏è No unauthorized buildings found ‚Äî skipping heatmap.")

# ‚úÖ Create PDF report
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")

pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section_body(f"{label}: {count} buildings")

pdf.section_title("3. Zoning & Detections")
pdf.image(overlay_output, x=10, y=None, w=180)

if heatmap_output:
    pdf.add_page()
    pdf.section_title("4. Predictive Heatmap")
    pdf.image(heatmap_output, x=10, y=None, w=180)

pdf.output(report_output)

print("‚úÖ Overlay Image:", overlay_output)
print("‚úÖ Heatmap Image:", heatmap_output if heatmap_output else "Skipped")
print("‚úÖ PDF Report:", report_output)

from google.colab import files

# Download all outputs
files.download("/content/overlayed_map.jpg")
if heatmap_output:
    files.download("/content/predictive_heatmap.jpg")
files.download("/content/classification_report.pdf")

import os, cv2, zipfile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF
from tqdm import tqdm

# ‚úÖ CONFIG PATHS
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
output_dir = "/content/final_outputs"
zip_path = "/content/final_output_bundle.zip"
os.makedirs(output_dir, exist_ok=True)

# ‚úÖ LOAD BASE INFO
df = pd.read_csv(predictions_path)
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ PDF Template
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

# ‚úÖ Start Processing Each Image
for image_name in tqdm(df['image'].unique()):
    image_path = os.path.join(image_folder, image_name)
    if not os.path.exists(image_path): continue
    image = cv2.imread(image_path)
    if image is None: continue

    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    height, width = image.shape[:2]
    base_name = os.path.splitext(image_name)[0]

    zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

    def draw_zone(polygon, color):
        coords = np.array([[(
            int((lon - min_lon) / (max_lon - min_lon) * width),
            int((max_lat - lat) / (max_lat - min_lat) * height)
        ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
        cv2.fillPoly(zone_overlay, coords, color)

    draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))
    draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))
    zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

    auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}
    unauthorized_points = []
    image_preds = df[df['image'] == image_name]

    for _, row in image_preds.iterrows():
        x1, y1, x2, y2 = int(row['x1']), int(row['y1']), int(row['x2']), int(row['y2'])
        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
        lon, lat = pixel_to_latlon(cx, cy, width, height)
        point = Point(lon, lat)

        if red_zone.contains(point).any():
            label = "Unauthorized"
            color = (255, 0, 0)
            unauthorized_points.append((lat, lon))
        elif yellow_zone.contains(point).any():
            label = "Authorized"
            color = (0, 255, 0)
        else:
            label = "Unclassified"
            color = (255, 255, 255)

        auth_counts[label] += 1
        cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
        cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    overlay_path = os.path.join(output_dir, f"overlayed_map_{base_name}.jpg")
    cv2.imwrite(overlay_path, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

    # ‚úÖ Generate heatmap
    heatmap_path = None
    if len(unauthorized_points) > 0:
        heat_df = pd.DataFrame(unauthorized_points, columns=["lat", "lon"])
        plt.figure(figsize=(10, 8))
        sns.kdeplot(
            data=heat_df, x="lon", y="lat",
            cmap="Reds", fill=True, bw_adjust=0.3, alpha=0.8
        )
        plt.title("Predictive Unauthorized Construction Heatmap")
        plt.xlim(min_lon, max_lon)
        plt.ylim(min_lat, max_lat)
        plt.xlabel("Longitude")
        plt.ylabel("Latitude")
        plt.grid(True)
        heatmap_path = os.path.join(output_dir, f"predictive_heatmap_{base_name}.jpg")
        plt.savefig(heatmap_path, dpi=300)
        plt.close()

    # ‚úÖ Generate PDF
    pdf = PDF()
    pdf.add_page()
    pdf.section_title("1. Zoning Summary")
    pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")
    pdf.section_title("2. Classification Result")
    for label, count in auth_counts.items():
        pdf.section_body(f"{label}: {count} buildings")
    pdf.section_title("3. Zoning & Detections")
    pdf.image(overlay_path, x=10, y=None, w=180)
    if heatmap_path:
        pdf.add_page()
        pdf.section_title("4. Predictive Heatmap")
        pdf.image(heatmap_path, x=10, y=None, w=180)

    pdf_path = os.path.join(output_dir, f"classification_report_{base_name}.pdf")
    pdf.output(pdf_path)

# ‚úÖ ZIP everything
with zipfile.ZipFile(zip_path, "w") as zipf:
    for root, _, files in os.walk(output_dir):
        for file in files:
            zipf.write(os.path.join(root, file), arcname=file)

print("‚úÖ ALL DONE!")
print("üì¶ Final output zipped at:", zip_path)

from google.colab import drive
drive.mount('/content/drive')

import shutil
import os

# Create a target folder in your Drive
target_dir = "/content/drive/MyDrive/final_detection_outputs"
os.makedirs(target_dir, exist_ok=True)

# Copy ZIP
shutil.copy("/content/final_output_bundle.zip", target_dir)

print("‚úÖ Uploaded to Google Drive at:", target_dir)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from shapely.geometry import Point
import geopandas as gpd

# ‚úÖ Load predictions
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(predictions_path)

# ‚úÖ Filter only unauthorized buildings
unauthorized_points = []

# Load red/yellow zone polygons
red_zone = gpd.read_file("/content/red_zone_real.geojson")
yellow_zone = gpd.read_file("/content/yellow_zone_real.geojson")

# Precomputed bounds (same used in your GIS setup)
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

# For image dimensions (use sample)
sample_image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/RGB-PanSharpen_AOI_3_Paris_img485.jpg"
import cv2
img = cv2.imread(sample_image_path)
height, width = img.shape[:2]

def pixel_to_latlon(x, y):
    lon = min_lon + (x / width) * (max_lon - min_lon)
    lat = max_lat - (y / height) * (max_lat - min_lat)
    return lon, lat

# Extract lat/lon for all unauthorized buildings
for _, row in df.iterrows():
    x1, y1, x2, y2 = int(row["x1"]), int(row["y1"]), int(row["x2"]), int(row["y2"])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        unauthorized_points.append((lat, lon))  # heatmaps = (Y, X) = (lat, lon)

# ‚úÖ Generate heatmap
if len(unauthorized_points) > 0:
    heat_df = pd.DataFrame(unauthorized_points, columns=["lat", "lon"])
    plt.figure(figsize=(10, 8))
    sns.kdeplot(
        data=heat_df, x="lon", y="lat",
        cmap="Reds", fill=True, bw_adjust=0.1, alpha=0.8, levels=200
    )
    plt.title("Predictive Unauthorized Construction Hotspot Map")
    plt.xlabel("Longitude")
    plt.ylabel("Latitude")
    plt.xlim(min_lon, max_lon)
    plt.ylim(min_lat, max_lat)
    plt.grid(True)
    plt.savefig("/content/predictive_heatmap.jpg", dpi=300)
    plt.show()

    print("‚úÖ Predictive heatmap saved to /content/predictive_heatmap.jpg")
else:
    print("‚ö†Ô∏è No unauthorized predictions found to generate heatmap.")

from google.colab import files
files.download("/content/overlayed_map.jpg")
files.download("/content/classification_report.pdf")

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF
import os

# ‚úÖ CONFIGURATION ‚Äî SET IMAGE NAME HERE
image_filename = "RGB-PanSharpen_AOI_3_Paris_img485.jpg"

# ‚úÖ CORRECT PATHS
image_path = f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/{image_filename}"
predictions_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/content/overlayed_map.jpg"
report_output = "/content/classification_report.pdf"

# ‚úÖ STEP 1: Load image with check
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"‚ùå Image not found at path: {image_path}")

image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# ‚úÖ STEP 2: Load zoning GeoJSONs
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# ‚úÖ STEP 3: Geo-coordinate mapper
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ STEP 4: Load predictions for this image
pred_df = pd.read_csv(predictions_path)
pred_df = pred_df[pred_df['image_name'] == image_filename]

# ‚úÖ STEP 5: Draw zoning overlay
zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))     # Red
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))  # Yellow

zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# ‚úÖ STEP 6: Draw building boxes
auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}

for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy, width, height)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ‚úÖ STEP 7: Save overlayed map
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# ‚úÖ STEP 8: Generate PDF report
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")

pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section_body(f"{label}: {count} buildings")

pdf.section_title("3. Map Overview")
pdf.image(overlay_output, x=10, y=None, w=180)

pdf.output(report_output)

# ‚úÖ Done!
print("‚úÖ Overlay map saved to:", overlay_output)
print("‚úÖ PDF report saved to:", report_output)

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
from fpdf import FPDF
import os

# ‚úÖ CONFIGURATION
image_filename = "RGB-PanSharpen_AOI_3_Paris_img485.jpg"
image_path = f"/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/RGB-PanSharpen/{image_filename}"
predictions_path = "/content/predictions.csv"  # Make sure you copied it from /mnt/data
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/content/overlayed_map.jpg"
report_output = "/content/classification_report.pdf"

# ‚úÖ STEP 1: Load the image
image = cv2.imread(image_path)
if image is None:
    raise FileNotFoundError(f"‚ùå Image not found at path: {image_path}")

image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# ‚úÖ STEP 2: Load zoning zones
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# ‚úÖ STEP 3: Geo-coordinate mapping
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# ‚úÖ STEP 4: Load predictions
pred_df = pd.read_csv(predictions_path)
pred_df = pred_df[pred_df['image_name'] == image_filename]

# ‚úÖ STEP 5: Draw zoning overlay
zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))     # Red
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))  # Yellow

zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# ‚úÖ STEP 6: Classify buildings and draw boxes
auth_counts = {"Authorized": 0, "Unauthorized": 0, "Unclassified": 0}

for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy, width, height)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# ‚úÖ STEP 7: Save the overlayed map
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# ‚úÖ STEP 8: Generate PDF report
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone = No construction allowed\nYellow Zone = Construction allowed")

pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section

pred_df = pred_df[pred_df['image_name'] == 'RGB-PanSharpen_AOI_3_Paris_img485.jpg']

import cv2
import numpy as np
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
from fpdf import FPDF
import os

# Paths
image_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/AOI_3_Paris_img485_RGB.jpg"
predictions_path = "/mnt/data/predictions.csv"
red_zone_path = "/content/red_zone_real.geojson"
yellow_zone_path = "/content/yellow_zone_real.geojson"
overlay_output = "/mnt/data/overlayed_map.jpg"
report_output = "/mnt/data/classification_report.pdf"

# Load image
image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
height, width, _ = image.shape

# Load zoning polygons
red_zone = gpd.read_file(red_zone_path)
yellow_zone = gpd.read_file(yellow_zone_path)

# Get geographic bounds for pixel-latlon mapping
min_lat = yellow_zone.total_bounds[1]
max_lat = red_zone.total_bounds[3]
min_lon = red_zone.total_bounds[0]
max_lon = red_zone.total_bounds[2]

def pixel_to_latlon(x, y, w, h):
    lon = min_lon + (x / w) * (max_lon - min_lon)
    lat = max_lat - (y / h) * (max_lat - min_lat)
    return lon, lat

# Load predictions and filter for this image
pred_df = pd.read_csv(predictions_path)
#pred_df = pred_df[pred_df['image_name'] == 'AOI_3_Paris_img485_RGB.jpg']
pred_df = pred_df[pred_df['image_name'] == 'RGB-PanSharpen_AOI_3_Paris_img485.jpg']


zone_overlay = np.zeros_like(image_rgb, dtype=np.uint8)

def draw_zone(polygon, color):
    coords = np.array([[(
        int((lon - min_lon) / (max_lon - min_lon) * width),
        int((max_lat - lat) / (max_lat - min_lat) * height)
    ) for lon, lat in polygon.exterior.coords]], dtype=np.int32)
    cv2.fillPoly(zone_overlay, coords, color)

# Draw zoning
draw_zone(red_zone.geometry.iloc[0], (255, 0, 0))     # Red
draw_zone(yellow_zone.geometry.iloc[0], (255, 255, 0))  # Yellow

# Overlay zoning on image
zoned_image = cv2.addWeighted(image_rgb, 1, zone_overlay, 0.3, 0)

# Classification and drawing
auth_counts = {"Authorized": 0, "Unauthorized": 0}
for _, row in pred_df.iterrows():
    x1, y1, x2, y2 = int(row['xmin']), int(row['ymin']), int(row['xmax']), int(row['ymax'])
    cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
    lon, lat = pixel_to_latlon(cx, cy, width, height)
    point = Point(lon, lat)

    if red_zone.contains(point).any():
        label = "Unauthorized"
        color = (255, 0, 0)
    elif yellow_zone.contains(point).any():
        label = "Authorized"
        color = (0, 255, 0)
    else:
        label = "Unclassified"
        color = (255, 255, 255)

    auth_counts[label] += 1
    cv2.rectangle(zoned_image, (x1, y1), (x2, y2), color, 2)
    cv2.putText(zoned_image, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

# Save the overlayed map
cv2.imwrite(overlay_output, cv2.cvtColor(zoned_image, cv2.COLOR_RGB2BGR))

# Create a simple classification report PDF
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(200, 10, 'Unauthorized Construction Detection Report', ln=True, align='C')

    def section_title(self, title):
        self.set_font('Arial', 'B', 11)
        self.cell(0, 10, title, ln=True)

    def section_body(self, text):
        self.set_font('Arial', '', 10)
        self.multi_cell(0, 10, text)
        self.ln()

pdf = PDF()
pdf.add_page()

pdf.section_title("1. Zoning Summary")
pdf.section_body("Red Zone: No construction allowed.\nYellow Zone: Construction allowed.")

pdf.section_title("2. Classification Result")
for label, count in auth_counts.items():
    pdf.section_body(f"{label}: {count} buildings")

pdf.section_title("3. Map Overview")
pdf.image(overlay_output, x=10, y=None, w=180)

pdf.output(report_output)

overlay_output, report_output

from shapely import wkt
from shapely.geometry import box

# Filter metadata for selected image
selected_image_id = "AOI_3_Paris_img485"
image_data = metadata_df[metadata_df['ImageId'] == selected_image_id]

# Convert WKT Geo column to shapely polygons
geo_polygons = image_data['PolygonWKT_Geo'].dropna().apply(wkt.loads)

# Combine all building polygons to get total bounding box of image area
combined_bounds = geo_polygons[0].bounds
for poly in geo_polygons[1:]:
    combined_bounds = (
        min(combined_bounds[0], poly.bounds[0]),
        min(combined_bounds[1], poly.bounds[1]),
        max(combined_bounds[2], poly.bounds[2]),
        max(combined_bounds[3], poly.bounds[3]),
    )

min_lon, min_lat, max_lon, max_lat = combined_bounds
mid_lat = min_lat + (max_lat - min_lat) * 0.6  # for zoning

# Create Red and Yellow zoning polygons using bounding box
red_zone_polygon = Polygon([
    (min_lon, mid_lat),
    (max_lon, mid_lat),
    (max_lon, max_lat),
    (min_lon, max_lat),
])

yellow_zone_polygon = Polygon([
    (min_lon, min_lat),
    (max_lon, min_lat),
    (max_lon, mid_lat),
    (min_lon, mid_lat),
])

# Save as GeoJSON files using Fiona
from shapely.geometry import mapping

red_zone_path = "/mnt/data/red_zone_real.geojson"
yellow_zone_path = "/mnt/data/yellow_zone_real.geojson"

schema = {'geometry': 'Polygon', 'properties': {'zone': 'str'}}

with fiona.open(red_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as red_file:
    red_file.write({
        'geometry': mapping(red_zone_polygon),
        'properties': {'zone': 'red'}
    })

with fiona.open(yellow_zone_path, 'w', driver='GeoJSON', crs='EPSG:4326', schema=schema) as yellow_file:
    yellow_file.write({
        'geometry': mapping(yellow_zone_polygon),
        'properties': {'zone': 'yellow'}
    })

(red_zone_path, yellow_zone_path)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Load predictions
csv_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"
df = pd.read_csv(csv_path)

# Midpoint of each prediction box
df['x_center'] = (df['x1'] + df['x2']) / 2
df['y_center'] = (df['y1'] + df['y2']) / 2

# Heatmap plot
plt.figure(figsize=(12, 10))
sns.kdeplot(
    x=df['x_center'],
    y=df['y_center'],
    weights=df['score'],  # Higher confidence = more influence
    cmap="YlOrRd",  # Yellow to Red
    fill=True,
    bw_adjust=0.8,   # Smoothness
    thresh=0.05,     # Threshold to ignore noise
    levels=100       # Detail level
)

# Formatting
plt.title("Predictive Heatmap of Detected Buildings", fontsize=16)
plt.xlabel("X (image space)")
plt.ylabel("Y (image space)")
plt.grid(True)
plt.colorbar(label="Density / Risk")

# Save the figure
heatmap_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/heatmap_predictions.png"
plt.savefig(heatmap_path, dpi=300)
plt.show()

print("‚úÖ Heatmap saved to:", heatmap_path)

'/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json'

import cv2
import numpy as np
import matplotlib.pyplot as plt

# === Paths ===
image_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks/seg_RGB-PanSharpen_AOI_3_Paris_img1396.jpg"
mask_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks/RGB-PanSharpen_AOI_3_Paris_img1396.png"

# === Load image and mask ===
image = cv2.imread(image_path)
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

# Convert BGR to RGB
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# === Create colored overlay ===
mask_colored = np.zeros_like(image_rgb)
mask_colored[mask > 0] = [255, 0, 0]  # Red overlay for detected buildings

# === Blend overlay ===
blended = cv2.addWeighted(image_rgb, 0.8, mask_colored, 0.5, 0)

# === Show side-by-side ===
plt.figure(figsize=(16, 6))
plt.subplot(1, 2, 1)
plt.imshow(image_rgb)
plt.title("Original Image")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(blended)
plt.title("Overlay: Mask on Image")
plt.axis("off")

plt.tight_layout()
plt.show()

import numpy as np
import cv2
import os

mask_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks/RGB-PanSharpen_AOI_3_Paris_img1396.png"
mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

print("Unique values in mask:", np.unique(mask))

import os

mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

print("üóÇ Sample files in mask_dir:")
print(os.listdir(mask_dir)[:10])

import os
import cv2
import numpy as np
from detectron2.engine import DefaultPredictor
from tqdm import tqdm

# Paths
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"
os.makedirs(output_dir, exist_ok=True)

# Confidence threshold
CONF_THRESH = 0.5
predictor.model.eval()

# Get all image paths
image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(".jpg")]

print(f"üîç Found {len(image_paths)} images.")
skipped = 0

for img_path in tqdm(image_paths, desc="Saving binary masks"):
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} (image not found)")
        skipped += 1
        continue

    outputs = predictor(im)
    instances = outputs["instances"].to("cpu")

    # Filter by score
    conf_mask = instances.scores > CONF_THRESH
    filtered = instances[conf_mask]

    if len(filtered) == 0:
        skipped += 1
        continue

    # Combine all masks into one binary mask
    full_mask = np.zeros(im.shape[:2], dtype=np.uint8)
    for mask in filtered.pred_masks:
        full_mask = np.logical_or(full_mask, mask.numpy())

    # Save binary mask
    save_path = os.path.join(output_dir, img_name.replace(".jpg", ".png"))
    cv2.imwrite(save_path, (full_mask * 255).astype(np.uint8))

print(f"‚úÖ Done. Skipped: {skipped}, Saved: {len(image_paths) - skipped}")

import os

visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/visual_masks"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/binary_masks"

# Get a sample of each
visual_sample = sorted([f for f in os.listdir(visual_dir) if f.endswith(".jpg")])[:5]
mask_sample = sorted([f for f in os.listdir(mask_dir) if f.endswith(".png")])[:5]

print("üñºÔ∏è Visual samples:")
for f in visual_sample:
    print("-", f)

print("\nüß± Binary Mask samples:")
for f in mask_sample:
    print("-", f)

import os
import cv2
import matplotlib.pyplot as plt

# === Define your folders ===
visual_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/deployment_output/visuals"
mask_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/deployment_output/binary_masks"

# === Get all visuals ===
visual_files = [f for f in os.listdir(visual_dir) if f.endswith(".jpg")]
print(f"üñºÔ∏è Found {len(visual_files)} visual predictions.")

# === Pick a sample to show ===
if not visual_files:
    print("‚ö†Ô∏è No visual images found.")
else:
    sample_file = visual_files[0]  # You can also randomize or choose a specific one

    # Remove prefix to match with mask name
    base_name = sample_file.replace("seg_", "").replace(".jpg", "")
    visual_path = os.path.join(visual_dir, sample_file)
    mask_path = os.path.join(mask_dir, f"{base_name}_mask.png")

    # Load images
    visual_img = cv2.imread(visual_path)
    mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    if visual_img is None:
        print("‚ö†Ô∏è Visual image not found.")
    elif mask_img is None:
        print("‚ö†Ô∏è Mask image not found.")
    else:
        visual_img = cv2.cvtColor(visual_img, cv2.COLOR_BGR2RGB)

        # Plot side-by-side
        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.imshow(visual_img)
        plt.title("üéØ Visual Prediction")
        plt.axis("off")

        plt.subplot(1, 2, 2)
        plt.imshow(mask_img, cmap='gray')
        plt.title("üß± Binary GIS Mask")
        plt.axis("off")

        plt.suptitle(f"Preview: {base_name}", fontsize=14)
        plt.tight_layout()
        plt.show()

for img_path in image_paths:
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî image not found.")
        continue

    outputs = predictor(im)

    if len(outputs["instances"]) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No detections.")
        continue

    instances = outputs["instances"].to("cpu")

    try:
        v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
        out = v.draw_instance_predictions(instances)
        save_path = os.path.join(batch_output_dir, f"maskrcnn_{img_name}")
        cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
    except IndexError:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî class index error.")
        continue

from detectron2.utils.visualizer import Visualizer

try:
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = v.draw_instance_predictions(instances)
    save_path = os.path.join(batch_output_dir, f"maskrcnn_{img_name}")
    cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
except IndexError:
    print(f"‚ö†Ô∏è Skipping {img_name} due to metadata class mismatch.")
    continue

# === SETUP ===
import os
import cv2
import json
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog

# === CONFIG ===
project_root = "/content/drive/MyDrive/projects/mask_rcnn_paris"
json_path = f"{project_root}/instances_train.json"
images_path = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = f"{project_root}/output"
model_weights_path = f"{output_dir}/model_final.pth"

# === STEP 1: Register dataset ===
register_coco_instances("buildings_paris", {}, json_path, images_path)
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# === STEP 2: Load config and weights ===
cfg = get_cfg()
cfg.merge_from_file("detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.DATASETS.TEST = ()
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
cfg.MODEL.WEIGHTS = model_weights_path

predictor = DefaultPredictor(cfg)

# === STEP 3: Load all .jpg images ===
image_folder = images_path
image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(".jpg")]
print("Total JPGs found:", len(image_files))

# === STEP 4: Run predictions + save visuals ===
predicted_images = []
predictions = []

batch_output_dir = os.path.join(output_dir, "batch_predictions")
os.makedirs(batch_output_dir, exist_ok=True)

for img_path in tqdm(image_files, desc="Running inference"):
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)

    if im is None:
        print(f"‚ùå Could not read {img_path}")
        continue

    output = predictor(im)
    instances = output["instances"].to("cpu")

    if len(instances) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No detections")
        continue

    # Save visual prediction
    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = v.draw_instance_predictions(instances)
    save_path = os.path.join(batch_output_dir, f"maskrcnn_{img_name}")
    cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

    predicted_images.append(img_path)
    predictions.append(instances)

# === STEP 5: Save to JSON/CSV ===
json_output_path = os.path.join(output_dir, "predictions.json")
csv_output_path = os.path.join(output_dir, "predictions.csv")

output_json = []
output_csv = []

for idx, img_path in enumerate(predicted_images):
    instances = predictions[idx]
    boxes = instances.pred_boxes.tensor.numpy()
    scores = instances.scores.numpy()
    classes = instances.pred_classes.numpy()
    img_name = os.path.basename(img_path)

    for i in range(len(boxes)):
        box = boxes[i].tolist()
        score = float(scores[i])
        cls_id = int(classes[i])
        cls_name = metadata.thing_classes[cls_id]

        # For JSON
        output_json.append({
            "image": img_name,
            "class": cls_name,
            "score": score,
            "bbox": box
        })

        # For CSV
        output_csv.append([
            img_name,
            cls_name,
            score,
            box[0], box[1], box[2], box[3]
        ])

# Save JSON
with open(json_output_path, "w") as f:
    json.dump(output_json, f, indent=2)

# Save CSV
df = pd.DataFrame(output_csv, columns=["image", "class", "score", "x1", "y1", "x2", "y2"])
df.to_csv(csv_output_path, index=False)

print("‚úÖ Export complete! JSON and CSV saved.")

# === Install Detectron2 if not already done ===
# !pip install detectron2 -q

import os
import json
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.data.datasets import register_coco_instances
from detectron2.data import MetadataCatalog
from detectron2.utils.visualizer import Visualizer

# === CONFIG ===
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
json_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/instances_train.json"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/batch_predictions"
os.makedirs(output_dir, exist_ok=True)

# === Register dataset and metadata ===
register_coco_instances("buildings_paris", {}, json_path, image_dir)
MetadataCatalog.get("buildings_paris").thing_classes = ["building"]
metadata = MetadataCatalog.get("buildings_paris")

# === Load Config and Weights ===
cfg = get_cfg()
cfg.MODEL.WEIGHTS = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/model_final.pth"

#cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
cfg.MODEL.WEIGHTS = os.path.join(output_dir, "model_final.pth")
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.DEVICE = "cuda" if cv2.cuda.getCudaEnabledDeviceCount() > 0 else "cpu"
predictor = DefaultPredictor(cfg)

# === Batch Prediction Loop ===
all_images = [f for f in os.listdir(image_dir) if f.endswith(".jpg")]
predicted_images, predictions = [], []

for img_name in tqdm(all_images, desc="Predicting"):
    img_path = os.path.join(image_dir, img_name)
    im = cv2.imread(img_path)
    if im is None:
        print(f"‚ö†Ô∏è Couldn't load: {img_name}")
        continue

    outputs = predictor(im)

    if len(outputs["instances"]) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No detections")
        continue

    predicted_images.append(img_name)
    predictions.append(outputs)

    vis = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
    out = vis.draw_instance_predictions(outputs["instances"].to("cpu"))
    out_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
    cv2.imwrite(out_path, out.get_image()[:, :, ::-1])

# === Export Predictions to JSON and CSV ===
json_data, csv_data = [], []

for idx, img_name in enumerate(predicted_images):
    instances = predictions[idx]["instances"].to("cpu")
    boxes = instances.pred_boxes.tensor.numpy()
    scores = instances.scores.numpy()
    classes = instances.pred_classes.numpy()

    for i in range(len(boxes)):
        bbox = boxes[i].tolist()
        json_data.append({
            "image": img_name,
            "class": int(classes[i]),
            "score": float(scores[i]),
            "bbox": bbox
        })
        csv_data.append([img_name, int(classes[i]), float(scores[i]), *bbox])

# Save JSON
json_path_out = os.path.join(output_dir, "predictions.json")
with open(json_path_out, "w") as f:
    json.dump(json_data, f, indent=2)

# Save CSV
df = pd.DataFrame(csv_data, columns=["image", "class", "score", "x1", "y1", "x2", "y2"])
df.to_csv(os.path.join(output_dir, "predictions.csv"), index=False)

print("‚úÖ All done! Masks saved. JSON & CSV exported.")

import os
import json
import csv
import numpy as np
from tqdm import tqdm
from detectron2.structures import Boxes


# === CONFIG ===
predictions_folder = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/batch_predictions"
json_output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json"
csv_output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"

# === Collect all predicted mask image files ===
predicted_images = [
    os.path.join(predictions_folder, f)
    for f in os.listdir(predictions_folder)
    if f.endswith(".jpg") or f.endswith(".png")
]
predicted_images.sort()

# === Simulated predictions list (replace with actual detection results) ===
# For now, we‚Äôll simulate it with dummy boxes for demonstration
# In real usage, load the original `predictions` list created from model output
# Example: predictions = predictor(im)
predictions = []

output_json = []
output_csv = []

for idx, img_path in tqdm(enumerate(predicted_images), total=len(predicted_images)):
    img_name = os.path.basename(img_path)

    # Replace with actual predictor output result for each image
    # e.g., instances = predictions[idx]["instances"].to("cpu")
    try:
        instances = predictions[idx]["instances"].to("cpu")
    except:
        print(f"‚ö†Ô∏è Prediction missing for {img_name}")
        continue

    boxes = instances.pred_boxes.tensor.numpy()
    scores = instances.scores.numpy()
    classes = instances.pred_classes.numpy()

    for i in range(len(boxes)):
        bbox = boxes[i].tolist()
        score = float(scores[i])
        class_id = int(classes[i])
        class_name = "building"  # You can later use MetadataCatalog lookup

        # Optional: Get polygon if available
        polygons = []
        if instances.has("pred_masks"):
            mask = instances.pred_masks[i].numpy()
            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                polygons.extend(contour.squeeze().tolist())  # flatten

        # Save to JSON
        output_json.append({
            "image": img_name,
            "class": class_name,
            "score": score,
            "bbox": [float(x) for x in bbox],
            "polygon": [float(p) for p in polygons] if polygons else []
        })

        # Save to CSV
        output_csv.append([
            img_name,
            class_name,
            score,
            *bbox
        ])

# === Save to JSON file ===
with open(json_output_path, 'w') as f:
    json.dump(output_json, f, indent=2)

# === Save to CSV file ===
with open(csv_output_path, 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(["image", "class", "score", "x1", "y1", "x2", "y2"])
    writer.writerows(output_csv)

print("‚úÖ Export complete! JSON and CSV saved.")

import os

json_output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.json"
csv_output_path = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/predictions.csv"

print("JSON exists:", os.path.exists(json_output_path))
print("CSV exists:", os.path.exists(csv_output_path))

# JSON
import json
with open(json_output_path, "r") as f:
    data = json.load(f)
    print("Sample JSON Entry:", data[0] if data else "Empty")

# CSV
import pandas as pd
df = pd.read_csv(csv_output_path)
print("CSV Preview:\n", df.head())

import os
import json
import csv
from detectron2.utils.visualizer import GenericMask

# üîÅ Inputs
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/batch_predictions"
json_output_path = os.path.join(output_dir, "mask_predictions.json")
csv_output_path = os.path.join(output_dir, "bbox_predictions.csv")

# üìÇ Get list of images
image_paths = sorted([os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(".jpg")])
print(f"Total images: {len(image_paths)}")

# üì¶ Storage
output_json = []
output_csv = []

# üß† Loop over each image
for img_path in image_paths:
    img_name = os.path.basename(img_path)
    im = cv2.imread(img_path)
    if im is None:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî cannot read")
        continue

    outputs = predictor(im)

    instances = outputs["instances"].to("cpu")
    if len(instances) == 0:
        print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No detections")
        continue

    for i in range(len(instances)):
        bbox = instances.pred_boxes[i].tensor.numpy().tolist()[0]
        score = float(instances.scores[i])
        class_name = "building"

        # Create polygon from binary mask
        mask = instances.pred_masks[i].numpy()
        generic_mask = GenericMask(mask, mask.shape[0], mask.shape[1])
        polygons = generic_mask.polygons[0] if generic_mask.polygons else []

        # ‚ûï JSON entry
        output_json.append({
            "image": img_name,
            "class": class_name,
            "score": score,
            "bbox": bbox,
            "polygon": polygons
        })

        # ‚ûï CSV entry
        output_csv.append([img_name, class_name, score, *bbox])

# üíæ Save
with open(json_output_path, 'w') as f:
    json.dump(output_json, f, indent=2)

with open(csv_output_path, 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['image', 'class', 'score', 'x1', 'y1', 'x2', 'y2'])
    writer.writerows(output_csv)

print("‚úÖ Export complete.")
print(f"üìÑ JSON: {json_output_path}")
print(f"üìä CSV : {csv_output_path}")

import json
import csv

output_json = []
output_csv = []

for idx, img_path in enumerate(predicted_images):  # paths of successful predictions
    img_name = os.path.basename(img_path)
    instances = predictions[idx]["instances"].to("cpu")

    for i in range(len(instances)):
        class_id = int(instances.pred_classes[i])
        score = float(instances.scores[i])
        bbox = instances.pred_boxes.tensor[i].tolist()
        segmentation = instances.pred_masks[i].numpy().astype(int).tolist()  # binary mask (or polygon if available)

        # For JSON
        output_json.append({
            "image": img_name,
            "class": "building",
            "score": score,
            "bbox": bbox,
            "mask": segmentation
        })

        # For CSV (bbox only)
        output_csv.append([img_name, "building", score, *bbox])

# üîΩ Save to Disk
with open('/content/drive/MyDrive/projects/mask_rcnn_paris/output/mask_predictions.json', 'w') as f:
    json.dump(output_json, f, indent=2)

with open('/content/drive/MyDrive/projects/mask_rcnn_paris/output/bbox_predictions.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['image', 'class', 'score', 'x1', 'y1', 'x2', 'y2'])
    writer.writerows(output_csv)

outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
outputs = predictor(im)

# ‚úÖ Skip if no instances are detected
if len(outputs["instances"]) == 0:
    print(f"‚ö†Ô∏è Skipping {img_name} ‚Äî No buildings detected.")
    continue

v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=0.8)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

save_path = os.path.join(output_dir, f"maskrcnn_{img_name}")
cv2.imwrite(save_path, out.get_image()[:, :, ::-1])

import cv2
import os
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog

# Define image folder and output folder
image_folder = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_folder = "/content/drive/MyDrive/projects/mask_rcnn_paris/output/batch_predictions"
os.makedirs(output_folder, exist_ok=True)

# Load model config
cfg = get_cfg()
cfg.merge_from_file("/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.MODEL.WEIGHTS = os.path.join(output_folder, "model_final.pth")  # update if different
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

predictor = DefaultPredictor(cfg)
metadata = MetadataCatalog.get("buildings_paris")

# Run prediction on all .jpg files
from glob import glob
image_paths = sorted(glob(os.path.join(image_folder, "*.jpg")))

for img_path in image_paths:
    im = cv2.imread(img_path)
    outputs = predictor(im)

    v = Visualizer(im[:, :, ::-1], metadata=metadata, scale=1.0)
    out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

    filename = os.path.basename(img_path)
    output_path = os.path.join(output_folder, f"maskrcnn_{filename}")
    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])

print("‚úÖ All segmentations saved to:", output_folder)

from detectron2.engine import DefaultPredictor

cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, "model_final.pth")
predictor = DefaultPredictor(cfg)

# Load test image
im = cv2.imread("/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images/AOI_3_Paris_img1017.jpg")
outputs = predictor(im)

# Visualize predictions
v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)
out = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2.imwrite("/content/drive/MyDrive/projects/mask_rcnn_paris/output/test_mask_rcnn.jpg", out.get_image()[:, :, ::-1])

register_coco_instances("buildings_paris", {}, json_path, images_path)

metadata = MetadataCatalog.get("buildings_paris")
dataset_dicts = DatasetCatalog.get("buildings_paris")

print(f"Total Samples: {len(dataset_dicts)}")

# ‚úÖ DETECTRON2 MASK R-CNN TRAINING FOR PARIS DATASET

# STEP 1: Install Detectron2
!pip install -q detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.0/index.html

# STEP 2: Imports
import os
import json
import cv2
import random
import torch
import detectron2
from detectron2.utils.visualizer import Visualizer
from detectron2.data.datasets import register_coco_instances
from detectron2.engine import DefaultTrainer
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.utils.visualizer import ColorMode
from detectron2.data import MetadataCatalog, DatasetCatalog

# STEP 3: Set paths
dataset_path = "/content/drive/MyDrive/projects/mask_rcnn_paris"
images_path = f"{dataset_path}/images"
json_path = f"{dataset_path}/instances_train.json"
output_dir = f"{dataset_path}/output"

# STEP 4: Register the COCO dataset
register_coco_instances("buildings_paris", {}, json_path, images_path)

# STEP 5: Config setup
cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
cfg.DATASETS.TRAIN = ("buildings_paris",)
cfg.DATASETS.TEST = ()
cfg.DATALOADER.NUM_WORKERS = 2
cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
cfg.SOLVER.IMS_PER_BATCH = 2
cfg.SOLVER.BASE_LR = 0.00025
cfg.SOLVER.MAX_ITER = 1000
cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only buildings
cfg.OUTPUT_DIR = output_dir

# Create output directory
os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)

# STEP 6: Start training
trainer = DefaultTrainer(cfg)
trainer.resume_or_load(resume=False)
trainer.train()

import json

with open("/content/drive/MyDrive/projects/mask_rcnn_paris/coco_annotations.json") as f:
    coco_data = json.load(f)

print("Images:", len(coco_data.get("images", [])))
print("Annotations:", len(coco_data.get("annotations", [])))
print("Categories:", len(coco_data.get("categories", [])))

import os
import glob
import geopandas as gpd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

# Paths
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson/buildings"
jpg_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
output_dir = "/content/drive/MyDrive/projects/visualized_buildings"

os.makedirs(output_dir, exist_ok=True)

geojson_files = glob.glob(os.path.join(geojson_dir, "*.geojson"))
jpg_files = glob.glob(os.path.join(jpg_dir, "*.jpg"))
jpg_map = {os.path.basename(f): f for f in jpg_files}

missing = []

# Loop through GeoJSON and find matching image using ID
for geo_path in geojson_files:
    geo_name = os.path.basename(geo_path)
    img_id = geo_name.split("buildings_")[-1].replace(".geojson", "")

    # Find matching image filename
    matching_img = None
    for file in jpg_map:
        if img_id in file:
            matching_img = jpg_map[file]
            break

    if matching_img is None:
        missing.append(img_id)
        print(f"‚ùå Missing image for {img_id}.jpg")
        continue

    # Load and plot
    image = np.array(Image.open(matching_img))
    gdf = gpd.read_file(geo_path)

    fig, ax = plt.subplots(figsize=(10, 10))
    ax.imshow(image)
    gdf.plot(ax=ax, facecolor='none', edgecolor='lime', linewidth=1)
    ax.set_title(img_id)
    ax.axis('off')

    save_path = os.path.join(output_dir, f"{img_id}.png")
    plt.savefig(save_path, bbox_inches='tight')
    plt.close()

print(f"\n‚úÖ Visualization complete and saved in '{output_dir}' folder.")



import os
import glob

# Try both potential locations
geojson_dirs = [
    "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson",
    "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/geojson"
]

for path in geojson_dirs:
    geojson_files = glob.glob(os.path.join(path, "*.geojson"))
    print(f"üìÅ {path} -> Found {len(geojson_files)} geojson files")

import os
import geopandas as gpd
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np

# Paths
image_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/jpg_images"
geojson_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris/AOI_3_Paris_Train/geojson"

# Load one image and corresponding geojson
sample_image_name = "RGB-PanSharpen_AOI_3_Paris_img843.jpg"  # Pick any valid one
image_path = os.path.join(image_dir, sample_image_name)
geojson_path = os.path.join(geojson_dir, sample_image_name.replace(".jpg", ".geojson"))

# Read image and geojson
image = np.array(Image.open(image_path))
gdf = gpd.read_file(geojson_path)

# Plot
fig, ax = plt.subplots(figsize=(10, 10))
ax.imshow(image)
gdf.boundary.plot(ax=ax, color='red', linewidth=1)
plt.title("Building Annotations over Image")
plt.axis('off')
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import os

project_dir = "/content/drive/MyDrive/Unauthorized_Construction_Detection"
folders = [
    "tiff_images",         # original TIFFs
    "jpg_images",          # converted JPGs
    "geojson",             # annotations
    "yolo_format",         # YOLOv8 labels
    "checkpoints",         # model weights
    "results",             # prediction outputs
    "mask_rcnn",           # for segmentation
    "predictive_analysis", # analytics results
    "maps"                 # GIS/heatmap visualizations
]

for folder in folders:
    os.makedirs(os.path.join(project_dir, folder), exist_ok=True)

print("‚úÖ Project folders created.")

from PIL import Image
import glob

tiff_dir = f"{project_dir}/tiff_images"
jpg_dir = f"{project_dir}/jpg_images"

tiff_files = glob.glob(f"{tiff_dir}/*.tif")

for tif_path in tiff_files:
    img = Image.open(tif_path)
    jpg_path = os.path.join(jpg_dir, os.path.basename(tif_path).replace(".tif", ".jpg"))
    img.convert("RGB").save(jpg_path, "JPEG")

print(f"‚úÖ Converted {len(tiff_files)} TIFF files to JPG.")

from PIL import Image
import os
import glob

# Set up project paths
project_dir = "/content/drive/MyDrive/projects/SN2_buildings_train_AOI_3_Paris"
tiff_dir = f"{project_dir}/tiff_images"
jpg_dir = f"{project_dir}/jpg_images"

# Create JPG output folder if it doesn't exist
os.makedirs(jpg_dir, exist_ok=True)

# Convert TIFFs to JPGs
tiff_files = glob.glob(f"{tiff_dir}/*.tif")
for tif_path in tiff_files:
    img = Image.open(tif_path)
    jpg_path = os.path.join(jpg_dir, os.path.basename(tif_path).replace(".tif", ".jpg"))
    img.convert("RGB").save(jpg_path, "JPEG")

print(f"‚úÖ Converted {len(tiff_files)} TIFF files to JPG.")